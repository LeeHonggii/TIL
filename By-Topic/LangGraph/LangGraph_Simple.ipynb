{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ LangGraph QuickStart - ì…ë¬¸ìë¥¼ ìœ„í•œ ì‹¤ì „ íŠœí† ë¦¬ì–¼\n",
    "\n",
    "## ğŸ¯ ëª©í‘œì™€ ëŒ€ìƒ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **LangGraph**ë¥¼ ì²˜ìŒ ì ‘í•˜ëŠ” ë¶„ì„ ìœ„í•œ **ì‹¤ì „ ì¤‘ì‹¬ íŠœí† ë¦¬ì–¼** ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“‹ ì´ íŠœí† ë¦¬ì–¼ì—ì„œ ë§Œë“¤ ê¸°ëŠ¥\n",
    "\n",
    "- **ğŸ§  ê¸°ì–µë ¥**: ì´ì „ ëŒ€í™”ë¥¼ ìœ ì§€í•˜ëŠ” ìƒíƒœ ê´€ë¦¬\n",
    "- **ğŸ” ê²€ìƒ‰ ì—°ë™**: ì™¸ë¶€ ê²€ìƒ‰ ë„êµ¬ë¡œ ìµœì‹  ì •ë³´ í™•ë³´\n",
    "- **ğŸ™‹ ì¸ê°„ ê°œì…**: ìŠ¹ì¸ ê¸°ë°˜ Human-in-the-Loop\n",
    "- **âªª ìƒíƒœ ì´ë ¥**: ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ë¡¤ë°± ë° ì¬ì‹¤í–‰\n",
    "\n",
    "### ğŸ—ºï¸ ì§„í–‰ ë¡œë“œë§µ\n",
    "\n",
    "- **ë‹¨ê³„ 1: ê¸°ë³¸ ì±—ë´‡ êµ¬ì¶•** â€“ StateGraph, ë©”ì‹œì§€ íë¦„\n",
    "- **ë‹¨ê³„ 2: ë„êµ¬ í†µí•©** â€“ Tool ë°”ì¸ë”©, ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n",
    "- **ë‹¨ê³„ 3: ë©”ëª¨ë¦¬ ì¶”ê°€** â€“ ì²´í¬í¬ì¸íŠ¸, Thread ID\n",
    "- **ë‹¨ê³„ 4: Human-in-the-Loop** â€“ interrupt, ìŠ¹ì¸ íë¦„\n",
    "- **ë‹¨ê³„ 5: ìƒíƒœ ì»¤ìŠ¤í„°ë§ˆì´ì§•** â€“ ì»¤ìŠ¤í…€ State, Tool ì—…ë°ì´íŠ¸\n",
    "- **ë‹¨ê³„ 6: ìƒíƒœ ì´ë ¥ ê´€ë¦¬** â€“ ì´ë ¥ íƒìƒ‰, ë¡¤ë°±, ì¬ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### ì¤€ë¹„ í•­ëª©\n",
    "\n",
    "1. **ğŸ”‘ API í‚¤ ì„¤ì •** â€“ OpenAI, Tavily, (ì„ íƒ) LangSmith\n",
    "2. **ğŸ“Š ì¶”ì  ì„¤ì •** â€“ LangSmithë¡œ ì‹¤í–‰ ì¶”ì  (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "# logging.langsmith(\"LangGraph-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ê¸°ë³¸ ì±—ë´‡ êµ¬ì¶• ğŸ¤–\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "\n",
    "ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœì˜ **ë©”ì‹œì§€ ê¸°ë°˜ ì±—ë´‡**ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "- **ğŸ—ºï¸ StateGraph**: ì „ì²´ íë¦„ ì •ì˜\n",
    "- **ğŸ“ State**: ë©”ì‹œì§€ ì €ì¥ êµ¬ì¡°\n",
    "- **ğŸ”¨ Node**: ì²˜ë¦¬ í•¨ìˆ˜ (LLM í˜¸ì¶œ)\n",
    "- **ğŸ›¤ï¸ Edge**: ì‹¤í–‰ ê²½ë¡œ ì—°ê²°\n",
    "- **âš™ï¸ Compile/Invoke**: ì‹¤í–‰ ì¤€ë¹„ ë° í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State ì •ì˜: ì±—ë´‡ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” íƒ€ì…\n",
    "class State(TypedDict):\n",
    "    \"\"\"ì±—ë´‡ì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” íƒ€ì…\n",
    "    \n",
    "    messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸\n",
    "    - add_messages í•¨ìˆ˜ë¥¼ í†µí•´ ìƒˆ ë©”ì‹œì§€ê°€ ì¶”ê°€ë¨ (ë®ì–´ì“°ê¸°ê°€ ì•„ë‹Œ ì¶”ê°€)\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# StateGraph ìƒì„±\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "print(\"âœ… StateGraph ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"ğŸ“Œ StateëŠ” messages í‚¤ë¥¼ ê°€ì§€ë©°, add_messages ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§  LLM ì„ íƒ ë° ì„¤ì •\n",
    "\n",
    "ì‹¤ìŠµì—ì„œëŠ” **GPT-4o**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì„ íƒ\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¨ ì±—ë´‡ ë…¸ë“œ ì¶”ê°€\n",
    "\n",
    "ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì…ë ¥ë°›ì•„ LLMì— ì „ë‹¬í•˜ê³ , ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìƒíƒœì— ì¶”ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"ì±—ë´‡ ë…¸ë“œ í•¨ìˆ˜\n",
    "    \n",
    "    í˜„ì¬ ìƒíƒœì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ LLMì— ì „ë‹¬í•˜ê³ ,\n",
    "    ì‘ë‹µì„ ìƒˆ ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    \n",
    "    # ì‘ë‹µì„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì—¬ ë°˜í™˜\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ì— ë…¸ë“œ ì¶”ê°€\n",
    "# ì²« ë²ˆì§¸ ì¸ì: ë…¸ë“œì˜ ê³ ìœ  ì´ë¦„\n",
    "# ë‘ ë²ˆì§¸ ì¸ì: ë…¸ë“œê°€ ì‚¬ìš©ë  ë•Œ í˜¸ì¶œë  í•¨ìˆ˜\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸšª ì§„ì…ì ê³¼ ì¢…ë£Œì  ì„¤ì •\n",
    "\n",
    "ì‹¤í–‰ ê²½ë¡œë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **START**: ì…ë ¥ ìˆ˜ì‹ \n",
    "- **chatbot**: LLM í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±\n",
    "- **END**: ê²°ê³¼ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§„ì…ì : ê·¸ë˜í”„ ì‹¤í–‰ì´ ì‹œì‘ë˜ëŠ” ì§€ì \n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# ì¢…ë£Œì : ê·¸ë˜í”„ ì‹¤í–‰ì´ ëë‚˜ëŠ” ì§€ì \n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "print(\"âœ… ì§„ì…ì ê³¼ ì¢…ë£Œì  ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"ğŸ“Œ ì‹¤í–‰ íë¦„: START â†’ chatbot â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš¡ ê·¸ë˜í”„ ì»´íŒŒì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‘€ ê·¸ë˜í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # ê·¸ë˜í”„ë¥¼ Mermaid í˜•ì‹ìœ¼ë¡œ ì‹œê°í™”\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"Graphvizê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‰ ì±—ë´‡ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "user_input = \"ì•ˆë…•í•˜ì„¸ìš”! LangGraphì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì…ë ¥ ë©”ì‹œì§€ ì¤€ë¹„\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=user_input)]\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "result = graph.invoke(inputs)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"User: {user_input}\\n\")\n",
    "print(f\"Assistant: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ë„êµ¬(Tools) ì¶”ê°€ ğŸ”§\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œ ìš”ì²­ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ì™¸ë¶€ ê²€ìƒ‰ ë„êµ¬ë¥¼ í†µí•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "- **Tool Binding**: LLMì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ ì—°ê²°\n",
    "- **Tool Node**: ì™¸ë¶€ API í˜¸ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ë…¸ë“œ\n",
    "- **Conditional Edges**: ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ìë™ìœ¼ë¡œ ë¶„ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ ë„êµ¬ ì˜ˆì‹œ\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ë”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool \n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ê³±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "tools = [add, multiply]\n",
    "\n",
    "print(f\"âœ… {len(tools)}ê°œì˜ ë„êµ¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ—ºï¸ ë„êµ¬ ì‚¬ìš© ê·¸ë˜í”„ êµ¬ì„±\n",
    "\n",
    "ê¸°ë³¸ íë¦„ì— ë„êµ¬ í˜¸ì¶œ ê²½ë¡œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ê¸°ì¡´: ì‚¬ìš©ì â†’ chatbot â†’ END\n",
    "- ë³€ê²½: ì‚¬ìš©ì â†’ chatbot â‡„ tools â†’ chatbot â†’ END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State ì •ì˜ (ë™ì¼)\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# ìƒˆë¡œìš´ ê·¸ë˜í”„ ë¹Œë” ìƒì„±\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# LLMì— ë„êµ¬ ë°”ì¸ë”© - LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì±—ë´‡ ë…¸ë“œ\"\"\"\n",
    "    # ë„êµ¬ê°€ ë°”ì¸ë”©ëœ LLM í˜¸ì¶œ\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ToolNode ì¶”ê°€ - ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ\n",
    "tool_node = ToolNode(tools=tools)\n",
    "builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸš¦ ì¡°ê±´ë¶€ ë¼ìš°íŒ…(Conditional Edges)\n",
    "\n",
    "ìš”ì²­ì— ë”°ë¼ ìë™ìœ¼ë¡œ ê²½ë¡œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ë„êµ¬ í˜¸ì¶œ í•„ìš”**: \"tools\" ë¡œ ì´ë™\n",
    "- **ë‚´ë¶€ ì²˜ë¦¬ ê°€ëŠ¥**: ì¢…ë£Œ\n",
    "\n",
    "í•µì‹¬: `tools_condition` ì´ ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ì˜ `tool_calls` ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€\n",
    "# tools_conditionì€ ë©”ì‹œì§€ì— tool_callsê°€ ìˆìœ¼ë©´ \"tools\"ë¡œ,\n",
    "# ì—†ìœ¼ë©´ ENDë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # ì‚¬ì „ ì •ì˜ëœ ì¡°ê±´ í•¨ìˆ˜ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "# ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì±—ë´‡ìœ¼ë¡œ ëŒì•„ê°€ê¸°\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# ì‹œì‘ì  ì„¤ì •\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph_with_tools = builder.compile()\n",
    "\n",
    "print(\"âœ… ë„êµ¬ê°€ í¬í•¨ëœ ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‘€ ì—…ê·¸ë ˆì´ë“œ ê·¸ë˜í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(graph_with_tools.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"ì‹œê°í™” ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸš€ ë„êµ¬ ì‚¬ìš© í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì§ˆë¬¸\n",
    "test_input = \"25 ë”í•˜ê¸° 17ì€ ì–¼ë§ˆì¸ê°€ìš”? ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ì— 3ì„ ê³±í•˜ë©´?\"\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=test_input)]\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "print(f\"User: {test_input}\\n\")\n",
    "print(\"ì²˜ë¦¬ ê³¼ì •:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰ ê³¼ì • í™•ì¸\n",
    "for event in graph_with_tools.stream(inputs):\n",
    "    for node_name, output in event.items():\n",
    "        if node_name == \"chatbot\":\n",
    "            message = output[\"messages\"][0]\n",
    "            if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "                print(f\"ğŸ¤– ì±—ë´‡: ë„êµ¬ í˜¸ì¶œ ìš”ì²­\")\n",
    "                for tool_call in message.tool_calls:\n",
    "                    print(f\"   - {tool_call['name']}({tool_call['args']})\")\n",
    "            else:\n",
    "                print(f\"ğŸ¤– ì±—ë´‡: {message.content}\")\n",
    "        elif node_name == \"tools\":\n",
    "            print(f\"ğŸ”§ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:\")\n",
    "            for msg in output[\"messages\"]:\n",
    "                print(f\"   - {msg.content}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Part 2 ìš”ì•½\n",
    "\n",
    "### í•™ìŠµí•œ ë‚´ìš©\n",
    "1. **ë„êµ¬ ì •ì˜**: `@tool` ë°ì½”ë ˆì´í„°ë¡œ í•¨ìˆ˜ë¥¼ ë„êµ¬ë¡œ ë³€í™˜\n",
    "2. **ë„êµ¬ ë°”ì¸ë”©**: `llm.bind_tools()`ë¡œ LLMì— ë„êµ¬ ì—°ê²°\n",
    "3. **ToolNode**: ë„êµ¬ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” íŠ¹ìˆ˜ ë…¸ë“œ\n",
    "4. **ì¡°ê±´ë¶€ ë¼ìš°íŒ…**: `tools_condition`ìœ¼ë¡œ ìë™ ë¶„ê¸°\n",
    "5. **ìˆœí™˜ êµ¬ì¡°**: ë„êµ¬ â†’ ì±—ë´‡ â†’ ë„êµ¬ì˜ ë°˜ë³µ ê°€ëŠ¥\n",
    "\n",
    "### ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ\n",
    "- ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ (ë‚ ì”¨, ì£¼ê°€, ë‰´ìŠ¤)\n",
    "- ê³„ì‚° ë° ë¶„ì„ ë„êµ¬ ì—°ë™\n",
    "- ì™¸ë¶€ API í˜¸ì¶œ (ê²€ìƒ‰, ë²ˆì—­, DB ì¡°íšŒ)\n",
    "- ë©€í‹°ìŠ¤í… ì‘ì—… ìë™í™”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}