{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere Reranker로 검색 결과 재정렬하기\n",
    "\n",
    "이 노트북에서는 Cohere의 재정렬(reranking) 모델을 사용하여 검색 결과의 품질을 향상시키는 방법을 학습합니다.\n",
    "\n",
    "## 학습 목표\n",
    "- Cohere의 다국어 임베딩 모델 이해\n",
    "- Cohere Reranker를 활용한 검색 결과 재정렬\n",
    "- ContextualCompressionRetriever 활용법\n",
    "\n",
    "## 주요 개념\n",
    "- **Reranking**: 초기 검색 결과를 재정렬하여 가장 관련성 높은 문서를 상위에 배치\n",
    "- **Contextual Compression**: 쿼리와 관련된 문서만 선택하고 압축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cohere 소개\n",
    "\n",
    ">[Cohere](https://cohere.ai/about)는 기업이 인간-기계 상호작용을 개선할 수 있도록 돕는 자연어 처리 모델을 제공하는 캐나다의 스타트업입니다.\n",
    "\n",
    "### Cohere 다국어 지원 모델\n",
    "\n",
    "**Embedding 모델:**\n",
    "- `embed-multilingual-v3.0`: 최신 다국어 임베딩 모델\n",
    "- `embed-multilingual-light-v3.0`: 경량화된 다국어 임베딩 모델\n",
    "- `embed-multilingual-v2.0`: 이전 버전 다국어 임베딩 모델\n",
    "\n",
    "**Reranker 모델:**\n",
    "- `rerank-multilingual-v3.0`: 최신 다국어 재정렬 모델\n",
    "- `rerank-multilingual-v2.0`: 이전 버전 다국어 재정렬 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 설치\n",
    "# !pip install langchain langchain-community langchain-cohere python-dotenv faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 API KEY 정보 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Cohere API 키 확인 (선택사항)\n",
    "# print(\"Cohere API Key loaded:\", \"COHERE_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 유틸리티 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    \"\"\"검색된 문서를 보기 좋게 출력하는 함수\"\"\"\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n{d.page_content}\" \n",
    "             for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 기본 검색기 구성\n",
    "\n",
    "먼저 문서를 로드하고, 분할한 후 FAISS 벡터 스토어에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# 문서 로드 (예제 파일 경로를 실제 파일로 변경해주세요)\n",
    "documents = TextLoader(\"../appendix-keywords.txt\").load()\n",
    "\n",
    "# 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # 각 청크의 최대 크기\n",
    "    chunk_overlap=100    # 청크 간 중복 크기\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"문서가 {len(texts)}개의 청크로 분할되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohere 임베딩 모델을 사용한 벡터 스토어 생성\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-multilingual-v3.0\"  # 다국어 임베딩 모델 사용\n",
    ")\n",
    "\n",
    "# FAISS 벡터 스토어 생성 및 검색기 초기화\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# 검색기 생성 (상위 10개 문서 검색)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 기본 검색 수행\n",
    "\n",
    "재정렬을 적용하기 전, 기본 검색 결과를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의문 설정\n",
    "query = \"Word2Vec에 대해서 알려줘!\"\n",
    "\n",
    "# 기본 검색 수행\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n🔍 쿼리: {query}\")\n",
    "print(f\"\\n📄 검색된 문서 수: {len(docs)}\\n\")\n",
    "print(\"=\" * 100)\n",
    "print(\"기본 검색 결과 (재정렬 전):\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# 검색 결과 출력\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cohere Reranker를 사용한 재정렬\n",
    "\n",
    "이제 `ContextualCompressionRetriever`와 `CohereRerank`를 사용하여 검색 결과를 재정렬합니다.\n",
    "\n",
    "### 재정렬의 장점:\n",
    "1. **정확도 향상**: 쿼리와 가장 관련성 높은 문서를 상위에 배치\n",
    "2. **노이즈 감소**: 관련 없는 문서 필터링\n",
    "3. **효율성**: 후속 처리에 필요한 문서 수 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "# Cohere 재정렬 모델 설정\n",
    "compressor = CohereRerank(\n",
    "    model=\"rerank-multilingual-v3.0\",  # 다국어 재정렬 모델\n",
    "    top_n=3  # 상위 3개 문서만 반환 (선택사항)\n",
    ")\n",
    "\n",
    "# 문맥 압축 검색기 생성\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,  # 재정렬 모델\n",
    "    base_retriever=retriever      # 기본 검색기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재정렬된 문서 검색\n",
    "compressed_docs = compression_retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n🔍 쿼리: {query}\")\n",
    "print(f\"\\n📄 재정렬 후 문서 수: {len(compressed_docs)}\\n\")\n",
    "print(\"=\" * 100)\n",
    "print(\"재정렬된 검색 결과 (Cohere Reranker 적용):\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# 재정렬된 결과 출력\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 재정렬 전후 비교\n",
    "\n",
    "재정렬이 검색 품질에 미치는 영향을 비교해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 쿼리로 테스트\n",
    "test_queries = [\n",
    "    \"Word2Vec에 대해서 알려줘!\",\n",
    "    \"임베딩이란 무엇인가?\",\n",
    "    \"트랜스포머 모델 설명해줘\"\n",
    "]\n",
    "\n",
    "for test_query in test_queries:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"쿼리: {test_query}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # 기본 검색\n",
    "    basic_docs = retriever.invoke(test_query)\n",
    "    print(f\"\\n기본 검색 - 상위 3개 문서:\")\n",
    "    for i, doc in enumerate(basic_docs[:3]):\n",
    "        content_preview = doc.page_content[:100] + \"...\"\n",
    "        print(f\"  {i+1}. {content_preview}\")\n",
    "    \n",
    "    # 재정렬 검색\n",
    "    reranked_docs = compression_retriever.invoke(test_query)\n",
    "    print(f\"\\n재정렬 후 - 상위 3개 문서:\")\n",
    "    for i, doc in enumerate(reranked_docs[:3]):\n",
    "        content_preview = doc.page_content[:100] + \"...\"\n",
    "        print(f\"  {i+1}. {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 고급 설정: 재정렬 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 설정으로 재정렬기 생성\n",
    "advanced_compressor = CohereRerank(\n",
    "    model=\"rerank-multilingual-v3.0\",\n",
    "    top_n=5,  # 상위 5개 문서 반환\n",
    "    # 추가 파라미터 설정 가능\n",
    ")\n",
    "\n",
    "# 고급 압축 검색기\n",
    "advanced_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=advanced_compressor,\n",
    "    base_retriever=retriever\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "advanced_docs = advanced_retriever.invoke(\"딥러닝과 머신러닝의 차이점\")\n",
    "print(f\"고급 설정으로 검색된 문서 수: {len(advanced_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 실습: 다양한 시나리오에서 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시나리오 1: 한국어 쿼리 처리\n",
    "korean_query = \"자연어 처리 기술에 대해 설명해주세요\"\n",
    "korean_docs = compression_retriever.invoke(korean_query)\n",
    "\n",
    "print(\"한국어 쿼리 처리 결과:\")\n",
    "print(f\"검색된 문서 수: {len(korean_docs)}\")\n",
    "if korean_docs:\n",
    "    print(f\"\\n최상위 문서 미리보기:\")\n",
    "    print(korean_docs[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시나리오 2: 영어 쿼리 처리\n",
    "english_query = \"What is embedding in NLP?\"\n",
    "english_docs = compression_retriever.invoke(english_query)\n",
    "\n",
    "print(\"\\n영어 쿼리 처리 결과:\")\n",
    "print(f\"검색된 문서 수: {len(english_docs)}\")\n",
    "if english_docs:\n",
    "    print(f\"\\n최상위 문서 미리보기:\")\n",
    "    print(english_docs[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 성능 비교 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def compare_retrieval_methods(query, retriever, compression_retriever):\n",
    "    \"\"\"기본 검색과 재정렬 검색의 성능을 비교하는 함수\"\"\"\n",
    "    \n",
    "    # 기본 검색 시간 측정\n",
    "    start_time = time.time()\n",
    "    basic_docs = retriever.invoke(query)\n",
    "    basic_time = time.time() - start_time\n",
    "    \n",
    "    # 재정렬 검색 시간 측정\n",
    "    start_time = time.time()\n",
    "    reranked_docs = compression_retriever.invoke(query)\n",
    "    rerank_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"\\n기본 검색:\")\n",
    "    print(f\"  - 소요 시간: {basic_time:.3f}초\")\n",
    "    print(f\"  - 검색된 문서 수: {len(basic_docs)}\")\n",
    "    \n",
    "    print(f\"\\n재정렬 검색:\")\n",
    "    print(f\"  - 소요 시간: {rerank_time:.3f}초\")\n",
    "    print(f\"  - 검색된 문서 수: {len(reranked_docs)}\")\n",
    "    print(f\"  - 시간 차이: +{rerank_time - basic_time:.3f}초\")\n",
    "    \n",
    "    return basic_docs, reranked_docs\n",
    "\n",
    "# 성능 비교 실행\n",
    "basic, reranked = compare_retrieval_methods(\n",
    "    \"Word2Vec 모델의 원리\",\n",
    "    retriever,\n",
    "    compression_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 요약 및 결론\n",
    "\n",
    "### 학습한 내용:\n",
    "1. **Cohere 임베딩 모델**: 다국어 텍스트를 벡터로 변환\n",
    "2. **Cohere Reranker**: 검색 결과를 재정렬하여 품질 향상\n",
    "3. **ContextualCompressionRetriever**: 기본 검색기와 재정렬기를 결합\n",
    "\n",
    "### 재정렬의 장점:\n",
    "- ✅ 더 정확한 검색 결과\n",
    "- ✅ 쿼리와의 관련성 향상\n",
    "- ✅ 노이즈 감소\n",
    "\n",
    "### 재정렬의 단점:\n",
    "- ⚠️ 추가적인 API 호출로 인한 지연\n",
    "- ⚠️ 추가 비용 발생 가능\n",
    "\n",
    "### 사용 시나리오:\n",
    "- 정확도가 중요한 검색 시스템\n",
    "- RAG (Retrieval-Augmented Generation) 파이프라인\n",
    "- 다국어 문서 검색 시스템\n",
    "- 엔터프라이즈 검색 솔루션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 추가 학습 자료\n",
    "\n",
    "- [Cohere 공식 문서](https://docs.cohere.com/)\n",
    "- [LangChain ContextualCompressionRetriever 문서](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/)\n",
    "- [Cohere Rerank API 문서](https://docs.cohere.com/docs/reranking)\n",
    "- [FAISS 벡터 데이터베이스 문서](https://github.com/facebookresearch/faiss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}