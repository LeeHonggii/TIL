{
"cells": [
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "# Pinecone VectorStore와 HybridSearch 구현\n",
   "\n",
   "Pinecone은 고성능 벡터 데이터베이스로, AI 및 머신러닝 애플리케이션을 위한 효율적인 벡터 저장 및 검색 솔루션입니다.\n",
   "\n",
   "이 노트북에서는 Pinecone을 활용한 하이브리드 검색(Dense + Sparse Vector) 구현 방법을 학습합니다."
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## Pinecone vs Chroma vs Faiss 비교\n",
   "\n",
   "### Pinecone의 장점\n",
   "\n",
   "1. **확장성**: 대규모 데이터셋에 대해 뛰어난 확장성을 제공합니다.\n",
   "2. **관리 용이성**: 완전 관리형 서비스로, 인프라 관리 부담이 적습니다.\n",
   "3. **실시간 업데이트**: 데이터의 실시간 삽입, 업데이트, 삭제가 가능합니다.\n",
   "4. **고가용성**: 클라우드 기반으로 높은 가용성과 내구성을 제공합니다.\n",
   "5. **API 친화적**: RESTful/Python API를 통해 쉽게 통합할 수 있습니다.\n",
   "\n",
   "### Pinecone의 단점\n",
   "\n",
   "1. **비용**: Chroma나 Faiss에 비해 상대적으로 비용이 높을 수 있습니다.\n",
   "2. **커스터마이징 제한**: 완전 관리형 서비스이기 때문에 세부적인 커스터마이징에 제한이 있을 수 있습니다.\n",
   "3. **데이터 위치**: 클라우드에 데이터를 저장해야 하므로, 데이터 주권 문제가 있을 수 있습니다.\n",
   "\n",
   "### 비교 요약\n",
   "\n",
   "- **Chroma/FAISS**: 오픈소스이며 로컬에서 실행 가능하여 초기 비용이 낮고 데이터 제어가 용이합니다. 커스터마이징의 자유도가 높습니다. 하지만 대규모 확장성 면에서는 Pinecone에 비해 제한적일 수 있습니다.\n",
   "\n",
   "- **선택 기준**: 프로젝트의 규모, 요구사항, 예산 등을 고려하여 결정해야 합니다. 대규모 프로덕션 환경에서는 Pinecone이 유리할 수 있지만, 소규모 프로젝트나 실험적인 환경에서는 Chroma나 Faiss가 더 적합할 수 있습니다.\n",
   "\n",
   "**참고 자료**\n",
   "- [Pinecone 공식 홈페이지](https://docs.pinecone.io/integrations/langchain)\n",
   "- [Pinecone 랭체인 통합](https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/)"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 환경 설정"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 1,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "True"
     ]
    },
    "execution_count": 1,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
   "from dotenv import load_dotenv\n",
   "\n",
   "# API 키 정보 로드\n",
   "load_dotenv()"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 한글 처리를 위한 불용어 사전\n",
   "\n",
   "한글 텍스트 처리를 위해 불용어(stopwords) 사전을 준비합니다. 이는 추후 토크나이저에서 사용됩니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 2,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "['아',\n",
      " '휴',\n",
      " '아이구',\n",
      " '아이쿠',\n",
      " '아이고',\n",
      " '어',\n",
      " '나',\n",
      " '우리',\n",
      " '저희',\n",
      " '따라',\n",
      " '의해',\n",
      " '을',\n",
      " '를',\n",
      " '에',\n",
      " '의',\n",
      " '가',\n",
      " '으로',\n",
      " '로',\n",
      " '에게',\n",
      " '뿐이다']"
     ]
    },
    "execution_count": 2,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "from langchain_teddynote.korean import stopwords\n",
   "\n",
   "# 한글 불용어 사전 불러오기 (불용어 사전 출처: https://www.ranks.nl/stopwords/korean)\n",
   "stopword = stopwords()\n",
   "stopword[:20]"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 데이터 전처리\n",
   "\n",
   "PDF 문서를 로드하고 적절한 크기로 분할합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 3,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "4"
     ]
    },
    "execution_count": 3,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "from langchain_community.document_loaders import PyMuPDFLoader\n",
   "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
   "import glob\n",
   "\n",
   "# 텍스트 분할기 설정\n",
   "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
   "\n",
   "split_docs = []\n",
   "\n",
   "# PDF 파일들을 로드하고 분할\n",
   "files = sorted(glob.glob(\"data/*.pdf\"))\n",
   "\n",
   "for file in files:\n",
   "    loader = PyMuPDFLoader(file)\n",
   "    split_docs.extend(loader.load_and_split(text_splitter))\n",
   "\n",
   "# 문서 개수 확인\n",
   "len(split_docs)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 4,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "'<ADsP 요약정리 및 오답노트>\\n-1과목-\\n(객관식)\\n데이터 마스킹 : 데이터의 속성은 유지한 채, 익명으로 생성\\nCinematch -> 넷플릭스에서 개발한 알고리즘\\n데이터마이닝 vs 머신러닝(딥러닝) 구분하기 다른거임\\n트레이딩, 공급, 수요예측 -> 에너지 산업\\nCRM -> 고객관계관리 데이터베이스 (기업내부)\\nERP -> 기업 전체를 통합적으로 관리하고 경영의 효율화 목적\\n빅데이터 가치측정 어려윤 이유 : 1) 데이터 재사용,재조합,다목적용 개발'"
     ]
    },
    "execution_count": 4,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "# 첫 번째 문서의 내용 확인\n",
   "split_docs[0].page_content"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 5,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "{'source': 'data\\\\ADsP.pdf',\n",
      " 'file_path': 'data\\\\ADsP.pdf',\n",
      " 'page': 0,\n",
      " 'total_pages': 1,\n",
      " 'format': 'PDF 1.4',\n",
      " 'title': '',\n",
      " 'author': '',\n",
      " 'subject': '',\n",
      " 'keywords': '',\n",
      " 'creator': '',\n",
      " 'producer': 'PyPDF2',\n",
      " 'creationDate': '',\n",
      " 'modDate': '',\n",
      " 'trapped': ''}"
     ]
    },
    "execution_count": 5,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "# 메타데이터 확인\n",
   "split_docs[0].metadata"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### 문서의 전처리\n",
   "\n",
   "Pinecone에 저장하기 위해 문서를 전처리합니다.\n",
   "\n",
   "- 필요한 `metadata` 정보를 추출합니다.\n",
   "- 최소 길이 이상의 데이터만 필터링합니다.\n",
   "- 문서의 `basename`을 사용할지 여부를 지정합니다. (파일 경로의 마지막 부분만 사용)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 6,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "application/vnd.jupyter.widget-view+json": {
      "model_id": "5a26c36156514709b5960d61d1db1184",
      "version_major": 2,
      "version_minor": 0
     },
     "text/plain": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    "metadata": {},
    "output_type": "display_data"
   }
  ],
  "source": [
   "from langchain_teddynote.community.pinecone import preprocess_documents\n",
   "\n",
   "# 문서 전처리: 메타데이터 추출 및 필터링\n",
   "contents, metadatas = preprocess_documents(\n",
   "    split_docs=split_docs,\n",
   "    metadata_keys=[\"source\", \"page\", \"author\"],  # 저장할 메타데이터 키\n",
   "    min_length=5,  # 최소 문서 길이\n",
   "    use_basename=True,  # 파일명만 사용\n",
   ")"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 7,
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "문서 개수: 4\n",
     "메타데이터 키: dict_keys(['source', 'page', 'author'])\n",
     "소스 예시: ['ADsP.pdf', 'ADsP.pdf', 'ADsP.pdf', 'ADsP.pdf']\n"
    ]
   }
  ],
  "source": [
   "# 전처리 결과 확인\n",
   "print(f\"문서 개수: {len(contents)}\")\n",
   "print(f\"메타데이터 키: {metadatas.keys()}\")\n",
   "print(f\"소스 예시: {metadatas['source'][:5]}\")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## Pinecone API 키 설정\n",
   "\n",
   "Pinecone을 사용하려면 API 키가 필요합니다.\n",
   "\n",
   "### API 키 발급 방법\n",
   "1. [Pinecone 웹사이트](https://app.pinecone.io/) 접속\n",
   "2. 프로필 → Account → Projects → Starter → API keys → 발급\n",
   "3. `.env` 파일에 다음과 같이 추가:\n",
   "   ```\n",
   "   PINECONE_API_KEY=\"YOUR_PINECONE_API_KEY\"\n",
   "   ```"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 새로운 VectorStore 인덱스 생성\n",
   "\n",
   "Pinecone의 새로운 인덱스를 생성합니다.\n",
   "\n",
   "**주의사항**\n",
   "- `metric`은 유사도 측정 방법을 지정합니다. HybridSearch를 사용할 경우 `dotproduct`로 설정해야 합니다.\n",
   "- `dimension`은 사용하는 임베딩 모델의 차원과 일치해야 합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 8,
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[create_index]\n",
     "{'dimension': 4096,\n",
     " 'index_fullness': 0.0,\n",
     " 'namespaces': {'': {'vector_count': 0}},\n",
     " 'total_vector_count': 0}\n"
    ]
   }
  ],
  "source": [
   "import os\n",
   "from langchain_teddynote.community.pinecone import create_index\n",
   "\n",
   "# Pinecone 인덱스 생성 (무료 Serverless)\n",
   "pc_index = create_index(\n",
   "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
   "    index_name=\"db-index\",  # 인덱스 이름\n",
   "    dimension=4096,  # Embedding 차원 (OpenAI: 1536, Upstage: 4096)\n",
   "    metric=\"dotproduct\",  # 유사도 측정 방법 (dotproduct, euclidean, cosine)\n",
   ")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### 유료 Pod 사용 예시 (선택사항)\n",
   "\n",
   "유료 Pod는 무료 Serverless Pod 대비 더 확장된 기능을 제공합니다.\n",
   "\n",
   "```python\n",
   "# 유료 Pod 사용 예시\n",
   "from pinecone import PodSpec\n",
   "\n",
   "pc_index = create_index(\n",
   "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
   "    index_name=\"teddynote-db-index2\",\n",
   "    dimension=4096,\n",
   "    metric=\"dotproduct\",\n",
   "    pod_spec=PodSpec(\n",
   "        environment=\"us-west1-gcp\", \n",
   "        pod_type=\"p1.x1\", \n",
   "        pods=1\n",
   "    ),\n",
   ")\n",
   "```\n",
   "\n",
   "참고: https://docs.pinecone.io/guides/indexes/choose-a-pod-type-and-size"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## Sparse Encoder 생성\n",
   "\n",
   "HybridSearch를 위해 Sparse Encoder를 생성합니다.\n",
   "- Kiwi 형태소 분석기와 한글 불용어 처리를 수행합니다.\n",
   "- BM25 알고리즘을 사용하여 Sparse Vector를 생성합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 9,
  "metadata": {},
  "outputs": [
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "[nltk_data] Downloading package stopwords to\n",
     "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
     "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
    ]
   }
  ],
  "source": [
   "from langchain_teddynote.community.pinecone import (\n",
   "    create_sparse_encoder,\n",
   "    fit_sparse_encoder,\n",
   ")\n",
   "\n",
   "# 한글 불용어 사전 + Kiwi 형태소 분석기를 사용하여 Sparse Encoder 생성\n",
   "sparse_encoder = create_sparse_encoder(stopwords(), mode=\"kiwi\")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### Sparse Encoder 학습\n",
   "\n",
   "생성한 Sparse Encoder에 문서 corpus를 학습시킵니다.\n",
   "학습된 인코더는 파일로 저장되어 나중에 쿼리 임베딩 시 사용됩니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 10,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "application/vnd.jupyter.widget-view+json": {
      "model_id": "243219343e8c4a9abb18c535ee216b7b",
      "version_major": 2,
      "version_minor": 0
     },
     "text/plain": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    "metadata": {},
    "output_type": "display_data"
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[fit_sparse_encoder]\n",
     "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
    ]
   }
  ],
  "source": [
   "# Sparse Encoder를 사용하여 contents를 학습\n",
   "saved_path = fit_sparse_encoder(\n",
   "    sparse_encoder=sparse_encoder, \n",
   "    contents=contents, \n",
   "    save_path=\"./sparse_encoder.pkl\"  # 인코더 저장 경로\n",
   ")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 임베딩 모델 설정\n",
   "\n",
   "Dense Vector를 생성하기 위한 임베딩 모델을 설정합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 11,
  "metadata": {},
  "outputs": [],
  "source": [
   "from langchain_openai import OpenAIEmbeddings\n",
   "from langchain_upstage import UpstageEmbeddings\n",
   "\n",
   "# 임베딩 모델 생성 (필요에 따라 선택)\n",
   "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
   "upstage_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## Pinecone 인덱스에 문서 업로드 (Upsert)\n",
   "\n",
   "전처리된 문서를 Pinecone 인덱스에 업로드합니다.\n",
   "각 문서는 다음 정보를 포함합니다:\n",
   "- `context`: 문서의 내용\n",
   "- `metadata`: 페이지 번호, 출처 등의 메타데이터\n",
   "- `values`: Dense Embedding (임베딩 모델을 통해 생성)\n",
   "- `sparse_values`: Sparse Embedding (BM25를 통해 생성)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 12,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "application/vnd.jupyter.widget-view+json": {
      "model_id": "ed4cb4e2b069496d900ddc9c01956231",
      "version_major": 2,
      "version_minor": 0
     },
     "text/plain": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    "metadata": {},
    "output_type": "display_data"
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[upsert_documents]\n",
     "{'dimension': 4096,\n",
     " 'index_fullness': 0.0,\n",
     " 'namespaces': {'teddynote-namespace-01': {'vector_count': 0}},\n",
     " 'total_vector_count': 0}\n",
     "CPU times: total: 93.8 ms\n",
     "Wall time: 2.75 s\n"
    ]
   }
  ],
  "source": [
   "%%time\n",
   "from langchain_teddynote.community.pinecone import upsert_documents\n",
   "\n",
   "# 문서를 Pinecone에 업로드\n",
   "upsert_documents(\n",
   "    index=pc_index,  # Pinecone 인덱스\n",
   "    namespace=\"teddynote-namespace-01\",  # Pinecone namespace\n",
   "    contents=contents,  # 전처리한 문서 내용\n",
   "    metadatas=metadatas,  # 전처리한 문서 메타데이터\n",
   "    sparse_encoder=sparse_encoder,  # Sparse encoder\n",
   "    embedder=upstage_embeddings,  # Dense embedder\n",
   "    batch_size=32,  # 배치 크기\n",
   ")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### 대용량 문서 병렬 업로드 (선택사항)\n",
   "\n",
   "대용량 문서를 빠르게 업로드하려면 병렬 처리를 사용할 수 있습니다.\n",
   "\n",
   "```python\n",
   "from langchain_teddynote.community.pinecone import upsert_documents_parallel\n",
   "\n",
   "upsert_documents_parallel(\n",
   "    index=pc_index,\n",
   "    namespace=\"teddynote-namespace-02\",\n",
   "    contents=contents,\n",
   "    metadatas=metadatas,\n",
   "    sparse_encoder=sparse_encoder,\n",
   "    embedder=upstage_embeddings,\n",
   "    batch_size=64,\n",
   "    max_workers=30,  # 병렬 처리 워커 수\n",
   ")\n",
   "```"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 인덱스 조회 및 관리\n",
   "\n",
   "`describe_index_stats` 메서드로 인덱스의 통계 정보를 확인할 수 있습니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 13,
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'teddynote-namespace-01': {'vector_count': 4}},\n",
      " 'total_vector_count': 4}"
     ]
    },
    "execution_count": 13,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "# 인덱스 통계 조회\n",
   "pc_index.describe_index_stats()"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### 네임스페이스 삭제\n",
   "\n",
   "필요한 경우 특정 네임스페이스의 모든 데이터를 삭제할 수 있습니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 14,
  "metadata": {},
  "outputs": [],
  "source": [
   "from langchain_teddynote.community.pinecone import delete_namespace\n",
   "\n",
   "# 네임스페이스 삭제 (필요시)\n",
   "# delete_namespace(\n",
   "#     pinecone_index=pc_index,\n",
   "#     namespace=\"teddynote-namespace-01\",\n",
   "# )"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 검색기(Retriever) 생성\n",
   "\n",
   "### PineconeKiwiHybridRetriever 초기화\n",
   "\n",
   "`PineconeKiwiHybridRetriever`는 Dense Vector와 Sparse Vector를 결합한 하이브리드 검색을 수행합니다.\n",
   "\n",
   "**주요 파라미터**\n",
   "- `index_name`: Pinecone 인덱스 이름\n",
   "- `namespace`: 사용할 네임스페이스\n",
   "- `api_key`: Pinecone API 키\n",
   "- `sparse_encoder_path`: 저장된 Sparse Encoder 파일 경로\n",
   "- `stopwords`: 불용어 리스트\n",
   "- `tokenizer`: 사용할 토크나이저 (기본값: \"kiwi\")\n",
   "- `embeddings`: Dense Embedding 모델\n",
   "- `top_k`: 반환할 최대 문서 수\n",
   "- `alpha`: Dense와 Sparse 벡터의 가중치 (0~1, 1에 가까울수록 Dense 가중치 높음)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 15,
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[init_pinecone_index]\n",
     "{'dimension': 4096,\n",
     " 'index_fullness': 0.0,\n",
     " 'namespaces': {'teddynote-namespace-01': {'vector_count': 0}},\n",
     " 'total_vector_count': 0}\n"
    ]
   }
  ],
  "source": [
   "import os\n",
   "from langchain_teddynote.korean import stopwords\n",
   "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
   "from langchain_upstage import UpstageEmbeddings\n",
   "\n",
   "# Pinecone 검색기 파라미터 초기화\n",
   "pinecone_params = init_pinecone_index(\n",
   "    index_name=\"db-index\",  # Pinecone 인덱스 이름\n",
   "    namespace=\"teddynote-namespace-01\",  # Pinecone Namespace\n",
   "    api_key=os.environ[\"PINECONE_API_KEY\"],  # Pinecone API Key\n",
   "    sparse_encoder_path=\"./sparse_encoder.pkl\",  # Sparse Encoder 저장경로\n",
   "    stopwords=stopwords(),  # 불용어 사전\n",
   "    tokenizer=\"kiwi\",  # 한글 토크나이저\n",
   "    embeddings=UpstageEmbeddings(\n",
   "        model=\"solar-embedding-1-large-query\"  # Query용 임베딩 모델\n",
   "    ),\n",
   "    top_k=5,  # Top-K 문서 반환 개수\n",
   "    alpha=0.5,  # alpha=0.75인 경우: Dense 75%, Sparse 25%\n",
   ")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### PineconeKiwiHybridRetriever 생성\n",
   "\n",
   "초기화된 파라미터를 사용하여 하이브리드 검색기를 생성합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 16,
  "metadata": {},
  "outputs": [],
  "source": [
   "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
   "\n",
   "# 검색기 생성\n",
   "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 검색 수행\n",
   "\n",
   "생성한 검색기를 사용하여 다양한 검색을 수행할 수 있습니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 17,
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "=== 문서 1 ===\n",
     "내용: <ADsP 요약정리 및 오답노트>\n",
     "-1과목-\n",
     "(객관식)\n",
     "데이터 마스킹 : 데이터의 속성은 유지한 채, 익명으로 생성\n",
     "Cinematch -> 넷플릭스에서 개발한 알고리즘\n",
     "데이터마이닝 vs 머신러닝(딥러닝) 구분하기 다른거임\n",
     "트레이딩, 공급, 수요예측 -> 에너지 산업\n",
     "CRM -> 고객관계관리 데이터베이스 (기업내부)\n",
     "ERP -> 기업 전체를 통합적으로 관리하고 경영의 효율화 목적\n",
     "빅데이터 가치측정 어려윤 이유 : 1) 데이터 재사용,재조합,다목적용 개발\n",
     "\n",
     "메타데이터: {'author': '', 'context': '<ADsP 요약정리 및 오답노트>\\n-1과목-\\n(객관식)\\n데이터 마스킹 : 데이터의 속성은 유지한 채, 익명으로 생성\\nCinematch -> 넷플릭스에서 개발한 알고리즘\\n데이터마이닝 vs 머신러닝(딥러닝) 구분하기 다른거임\\n트레이딩, 공급, 수요예측 -> 에너지 산업\\nCRM -> 고객관계관리 데이터베이스 (기업내부)\\nERP -> 기업 전체를 통합적으로 관리하고 경영의 효율화 목적\\n빅데이터 가치측정 어려윤 이유 : 1) 데이터 재사용,재조합,다목적용 개발', 'page': 0.0, 'source': 'ADsP.pdf'}\n",
     "\n",
     "====================\n",
     "\n",
     "=== 문서 2 ===\n",
     "내용: 빅데이터 가치측정 어려윤 이유 : 1) 데이터 재사용,재조합,다목적용 개발\n",
     "                                          2) 새로운 가치 창출\n",
     "                                          3) 분석 기술 발전\n",
     "cf. 전문인력증가는 가치측정과 관련 없음\n",
     "사생활 침해를 막기 위한 개인정보 무작위 처리 (본래 목적 외에 사용 방지기술) -> 난수화\n",
     "유형분석 -> 특성에따라 분류할때 사용한다.\n",
     "핀테크(금융)분야에서 빅데이터 활용의 핵심분야 -> 신용평가\n",
     "\n",
     "메타데이터: {'author': '', 'context': '빅데이터 가치측정 어려윤 이유 : 1) 데이터 재사용,재조합,다목적용 개발\\n                                          2) 새로운 가치 창출\\n                                          3) 분석 기술 발전\\ncf. 전문인력증가는 가치측정과 관련 없음\\n사생활 침해를 막기 위한 개인정보 무작위 처리 (본래 목적 외에 사용 방지기술) -> 난수화\\n유형분석 -> 특성에따라 분류할때 사용한다.\\n핀테크(금융)분야에서 빅데이터 활용의 핵심분야 -> 신용평가', 'page': 0.0, 'source': 'ADsP.pdf'}\n",
     "\n",
     "====================\n",
     "\n",
     "=== 문서 3 ===\n",
     "내용: 핀테크(금융)분야에서 빅데이터 활용의 핵심분야 -> 신용평가\n",
     "K-NN 분석기법 - 딥러닝과 관련 x\n",
     "LSTM, Autoencoder, RNN -> 딥러닝과 관련 o\n",
     "Caffe, Tnsorflow, Theano -> 딥러닝 관련된 오픈소스\n",
     "Anaconda -> 머신러닝 관련된 오픈소스\n",
     "책임 원칙의 훼손 -> 일어나지도 않은 일을 예측해서 행동함 (범행 전에 체포, 신용불량 전에 \n",
     "대출금지)\n",
     "멀티미디어 등 복잡한 데이터베이스 관리 -> 객체지향 DBMS\n",
     "cf. 일반적으로 사용되는 테이블 기반 -> 관계형 DBMS\n",
     "\n",
     "메타데이터: {'author': '', 'context': '핀테크(금융)분야에서 빅데이터 활용의 핵심분야 -> 신용평가\\nK-NN 분석기법 - 딥러닝과 관련 x\\nLSTM, Autoencoder, RNN -> 딥러닝과 관련 o\\nCaffe, Tnsorflow, Theano -> 딥러닝 관련된 오픈소스\\nAnaconda -> 머신러닝 관련된 오픈소스\\n책임 원칙의 훼손 -> 일어나지도 않은 일을 예측해서 행동함 (범행 전에 체포, 신용불량 전에 \\n대출금지)\\n멀티미디어 등 복잡한 데이터베이스 관리 -> 객체지향 DBMS\\ncf. 일반적으로 사용되는 테이블 기반 -> 관계형 DBMS', 'page': 0.0, 'source': 'ADsP.pdf'}\n",
     "\n",
     "====================\n",
     "\n",
     "=== 문서 4 ===\n",
     "내용: cf. 일반적으로 사용되는 테이블 기반 -> 관계형 DBMS\n",
     "데이터 시각화 -> 비즈니스 컨설팅 영역 (IT영역 X)\n",
     "\n",
     "메타데이터: {'author': '', 'context': 'cf. 일반적으로 사용되는 테이블 기반 -> 관계형 DBMS\\n데이터 시각화 -> 비즈니스 컨설팅 영역 (IT영역 X)', 'page': 0.0, 'source': 'ADsP.pdf'}\n",
     "\n",
     "====================\n",
     "\n"
    ]
   }
  ],
  "source": [
   "# 기본 검색 수행\n",
   "search_results = pinecone_retriever.invoke(\"데이터 마스킹 관련 정보에 대해서 알려줘\")\n",
   "\n",
   "# 검색 결과 출력\n",
   "for i, result in enumerate(search_results, 1):\n",
   "    print(f\"=== 문서 {i} ===\")\n",
   "    print(f\"내용: {result.page_content}\")\n",
   "    print(f\"\\n메타데이터: {result.metadata}\")\n",
   "    print(\"\\n====================\\n\")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### 동적 검색 파라미터 사용\n",
   "\n",
   "`search_kwargs`를 사용하여 검색 시 동적으로 파라미터를 조정할 수 있습니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 18,
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "검색된 문서 수: 1\n"
    ]
   }
  ],
  "source": [
   "# k 파라미터를 사용하여 반환 문서 수 제한\n",
   "search_results = pinecone_retriever.invoke(\n",
   "    \"데이터 관련 정보에 대해서 알려줘\", \n",
   "    search_kwargs={\"k\": 1}  # 1개 문서만 반환\n",
   ")\n",
   "print(f\"검색된 문서 수: {len(search_results)}\")"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 19,
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "Dense 벡터만 사용한 검색 결과:\n",
     "<ADsP 요약정리 및 오답노트>\n",
     "-1과목-\n",
     "(객관식)\n",
     "데이터 마스킹 : 데이터의 속성은 유지한 채, 익명으로 생성\n",
     "...\n"
    ]
   }
  ],
  "source": [
   "# alpha 파라미터를 사용하여 Dense/Sparse 가중치 조정\n",
   "# alpha=1: Dense Vector만 사용\n",
   "# alpha=0: Sparse Vector만 사용\n",
   "search_results = pinecone_retriever.invoke(\n",
   "    \"데이터마스킹\", \n",
   "    search_kwargs={\"alpha\": 1, \"k\": 1}  # Dense Vector만 사용\n",
   ")\n",
   "print(\"Dense 벡터만 사용한 검색 결과:\")\n",
   "print(search_results[0].page_content[:100] + \"...\")"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "### 메타데이터 필터링\n",
   "\n",
   "메타데이터를 기준으로 검색 결과를 필터링할 수 있습니다.\n",
   "\n",
   "**주의**: 메타데이터 필터링은 Pinecone 유료 플랜에서만 사용 가능합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 20,
  "metadata": {},
  "outputs": [],
  "source": [
   "# 페이지 필터링 예시 (page < 5인 문서만 검색)\n",
   "# search_results = pinecone_retriever.invoke(\n",
   "#     \"데이터 관련 내용을 알려줘\",\n",
   "#     search_kwargs={\n",
   "#         \"filter\": {\"page\": {\"$lt\": 5}}, \n",
   "#         \"k\": 2\n",
   "#     },\n",
   "# )\n",
   "\n",
   "# 특정 소스 문서에서만 검색\n",
   "# search_results = pinecone_retriever.invoke(\n",
   "#     \"데이터 마스킹 관련 내용을 알려줘\",\n",
   "#     search_kwargs={\n",
   "#         \"filter\": {\"source\": {\"$eq\": \"ADsP.pdf\"}},\n",
   "#         \"k\": 3,\n",
   "#     },\n",
   "# )"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## Reranking 적용 (실험적 기능)\n",
   "\n",
   "검색 결과를 재순위화하여 더 정확한 결과를 얻을 수 있습니다.\n",
   "\n",
   "**주의**: 이 기능은 Pinecone 라이브러리 의존성에 따라 작동하지 않을 수 있습니다.\n",
   "\n",
   "```python\n",
   "# BGE-reranker-v2-m3 모델을 사용한 재순위화\n",
   "reranked_results = pinecone_retriever.invoke(\n",
   "    \"검색 쿼리\",\n",
   "    search_kwargs={\n",
   "        \"rerank\": True, \n",
   "        \"rerank_model\": \"bge-reranker-v2-m3\", \n",
   "        \"top_n\": 3\n",
   "    },\n",
   ")\n",
   "```\n",
   "\n",
   "참고: https://docs.pinecone.io/guides/inference/rerank"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "## 요약\n",
   "\n",
   "이 노트북에서는 다음 내용을 학습했습니다:\n",
   "\n",
   "1. **Pinecone 소개**: 클라우드 기반 벡터 데이터베이스의 특징과 장단점\n",
   "2. **인덱스 생성**: Pinecone 인덱스 생성 및 설정 방법\n",
   "3. **문서 전처리**: PDF 문서 로드, 분할, 메타데이터 추출\n",
   "4. **Sparse Encoder**: BM25 기반 Sparse Vector 생성\n",
   "5. **문서 업로드**: Dense + Sparse Vector를 활용한 하이브리드 인덱싱\n",
   "6. **하이브리드 검색**: PineconeKiwiHybridRetriever를 사용한 검색\n",
   "7. **고급 기능**: 동적 파라미터, 메타데이터 필터링, Reranking\n",
   "\n",
   "Pinecone의 하이브리드 검색은 Dense Vector의 의미적 유사성과 Sparse Vector의 키워드 매칭을 결합하여 더 정확한 검색 결과를 제공합니다."
  ]
 }
],
"metadata": {
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.11.0"
 }
},
"nbformat": 4,
"nbformat_minor": 4
}