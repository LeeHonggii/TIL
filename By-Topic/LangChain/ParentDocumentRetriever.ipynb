{
"cells": [
 {
  "cell_type": "markdown",
  "id": "tutorial-header",
  "metadata": {},
  "source": [
   "# ParentDocumentRetriever Tutorial\n",
   "\n",
   "ParentDocumentRetriever를 활용하여 계층적 문서 검색을 구현하는 방법을 학습합니다.\n",
   "\n",
   "## 📚 학습 목표\n",
   "- ParentDocumentRetriever의 개념과 필요성 이해\n",
   "- 문서 분할과 검색의 균형점 찾기\n",
   "- 계층적 문서 구조를 활용한 효율적인 검색 구현\n",
   "\n",
   "## 📋 주요 내용\n",
   "1. ParentDocumentRetriever 개념\n",
   "2. 전체 문서 검색 구현\n",
   "3. 계층적 청크 크기 조절\n",
   "4. 작은 청크로 검색하고 큰 청크로 반환하는 전략"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "concept-explanation",
  "metadata": {},
  "source": [
   "## 1. Parent Document Retriever 개념\n",
   "\n",
   "### 문서 검색과 문서 분할의 균형 잡기\n",
   "\n",
   "문서 검색 과정에서 문서를 적절한 크기의 조각(청크)으로 나누는 것은 다음의 **상충되는 두 가지 중요한 요소를 고려**해야 합니다.\n",
   "\n",
   "1. **작은 문서를 원하는 경우**: 이렇게 하면 문서의 임베딩이 그 의미를 가장 정확하게 반영할 수 있습니다. 문서가 너무 길면 임베딩이 의미를 잃어버릴 수 있습니다.\n",
   "2. **각 청크의 맥락이 유지되도록 충분히 긴 문서를 원하는 경우**: 너무 작은 청크는 전체 맥락을 잃을 수 있습니다.\n",
   "\n",
   "### `ParentDocumentRetriever`의 역할\n",
   "\n",
   "이 두 요구 사항 사이의 균형을 맞추기 위해 `ParentDocumentRetriever`라는 도구가 사용됩니다. 이 도구는:\n",
   "- 문서를 작은 조각으로 나누고, 이 조각들을 관리합니다\n",
   "- 검색을 진행할 때는, 먼저 이 작은 조각들을 찾아냅니다\n",
   "- 이 조각들이 속한 원본 문서(또는 더 큰 조각)의 식별자(ID)를 통해 전체적인 맥락을 파악합니다\n",
   "\n",
   "여기서 '부모 문서'란, 작은 조각이 나누어진 원본 문서를 말합니다. 이는 전체 문서일 수도 있고, 비교적 큰 다른 조각일 수도 있습니다.\n",
   "\n",
   "### 정리\n",
   "\n",
   "- **문서 간의 계층 구조 활용**: `ParentDocumentRetriever`는 문서 검색의 효율성을 높이기 위해 문서 간의 계층 구조를 활용합니다.\n",
   "- **검색 성능 향상**: 관련성 높은 문서를 빠르게 찾아내며, 주어진 질문에 대한 가장 적합한 답변을 제공하는 문서를 효과적으로 찾아낼 수 있습니다."
  ]
 },
 {
  "cell_type": "markdown",
  "id": "setup-section",
  "metadata": {},
  "source": [
   "## 2. 환경 설정 및 필요 라이브러리 임포트"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "id": "env-setup",
  "metadata": {},
  "outputs": [],
  "source": [
   "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
   "from dotenv import load_dotenv\n",
   "\n",
   "# API 키 정보 로드\n",
   "load_dotenv()"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 1,
  "id": "imports",
  "metadata": {},
  "outputs": [],
  "source": [
   "from langchain.storage import InMemoryStore\n",
   "from langchain_community.document_loaders import TextLoader\n",
   "from langchain_chroma import Chroma\n",
   "from langchain_openai import OpenAIEmbeddings\n",
   "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
   "from langchain.retrievers import ParentDocumentRetriever"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "data-loading-section",
  "metadata": {},
  "source": [
   "## 3. 데이터 로드"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 2,
  "id": "load-documents",
  "metadata": {},
  "outputs": [],
  "source": [
   "loaders = [\n",
   "    # 파일을 로드합니다.\n",
   "    TextLoader(\"../appendix-keywords.txt\"),\n",
   "]\n",
   "\n",
   "docs = []\n",
   "for loader in loaders:\n",
   "    # 로더를 사용하여 문서를 로드하고 docs 리스트에 추가합니다.\n",
   "    docs.extend(loader.load())"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "full-doc-retrieval",
  "metadata": {},
  "source": [
   "## 4. 전체 문서 검색\n",
   "\n",
   "이 모드에서는 전체 문서를 검색하고자 합니다. 따라서 `child_splitter` 만 지정하도록 하겠습니다.\n",
   "\n",
   "- 나중에는 `parent_splitter` 도 지정하여 결과를 비교해 보겠습니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 3,
  "id": "create-full-doc-retriever",
  "metadata": {},
  "outputs": [],
  "source": [
   "# 자식 분할기를 생성합니다.\n",
   "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
   "\n",
   "# DB를 생성합니다.\n",
   "vectorstore = Chroma(\n",
   "    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings()\n",
   ")\n",
   "\n",
   "store = InMemoryStore()\n",
   "\n",
   "# Retriever 를 생성합니다.\n",
   "retriever = ParentDocumentRetriever(\n",
   "    vectorstore=vectorstore,\n",
   "    docstore=store,\n",
   "    child_splitter=child_splitter,\n",
   ")"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "add-docs-explanation",
  "metadata": {},
  "source": [
   "### 문서 추가\n",
   "\n",
   "`retriever.add_documents(docs, ids=None)` 함수로 문서목록을 추가합니다.\n",
   "\n",
   "- `ids` 가 `None` 이면 자동으로 생성됩니다.\n",
   "- `add_to_docstore=False` 로 설정시 document 를 중복으로 추가하지 않습니다. 단, 중복을 체크하기 위한 `ids` 값이 필수 값으로 요구됩니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 4,
  "id": "add-documents",
  "metadata": {},
  "outputs": [],
  "source": [
   "# 문서를 검색기에 추가합니다. docs는 문서 목록이고, ids는 문서의 고유 식별자 목록입니다.\n",
   "retriever.add_documents(docs, ids=None, add_to_docstore=True)"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "check-store-keys",
  "metadata": {},
  "source": [
   "### 저장소 키 확인\n",
   "\n",
   "이 코드는 추가된 문서의 키를 반환합니다.\n",
   "- `store` 객체의 `yield_keys()` 메서드를 호출하여 반환된 키(key) 값들을 리스트로 변환합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 5,
  "id": "check-keys",
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "['7416183f-aade-4a33-bb75-709998516d08']"
     ]
    },
    "execution_count": 5,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "# 저장소의 모든 키를 리스트로 반환합니다.\n",
   "list(store.yield_keys())"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "vector-search-section",
  "metadata": {},
  "source": [
   "### 벡터스토어 직접 검색"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 6,
  "id": "vector-similarity-search",
  "metadata": {},
  "outputs": [],
  "source": [
   "# 유사도 검색을 수행합니다.\n",
   "sub_docs = vectorstore.similarity_search(\"Word2Vec\")"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 10,
  "id": "display-sub-doc",
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
     "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
     "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n"
    ]
   }
  ],
  "source": [
   "# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
   "print(sub_docs[0].page_content)"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "retriever-search-section",
  "metadata": {},
  "source": [
   "### ParentDocumentRetriever를 통한 검색\n",
   "\n",
   "이제 전체 retriever에서 검색해 보겠습니다. 이 과정에서는 작은 청크(chunk)들이 위치한 **문서를 반환** 하기 때문에 상대적으로 큰 문서들이 반환될 것입니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 11,
  "id": "retriever-invoke",
  "metadata": {},
  "outputs": [],
  "source": [
   "# 문서를 검색하여 가져옵니다.\n",
   "retrieved_docs = retriever.invoke(\"Word2Vec\")"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 12,
  "id": "display-retrieved-doc",
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "문서의 길이: 5733\n",
     "\n",
     "=====================\n",
     "\n",
     " 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
     "연관키워드: 혁신, 기술, 비즈니스 모델\n",
     "\n",
     "Crawling\n",
     "\n",
     "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
     "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
     "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
     "\n",
     "Word2Vec\n",
     "\n",
     "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
     "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
     "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
     "LLM (Large Language Model)\n",
     "\n",
     "정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을\n"
    ]
   }
  ],
  "source": [
   "# 검색된 문서의 문서의 페이지 내용의 길이를 출력합니다.\n",
   "print(\n",
   "    f\"문서의 길이: {len(retrieved_docs[0].page_content)}\",\n",
   "    end=\"\\n\\n=====================\\n\\n\",\n",
   ")\n",
   "\n",
   "# 문서의 일부를 출력합니다.\n",
   "print(retrieved_docs[0].page_content[2000:2500])"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "chunk-size-control",
  "metadata": {},
  "source": [
   "## 5. 더 큰 Chunk 의 크기를 조절\n",
   "\n",
   "이전의 결과처럼 **전체 문서가 너무 커서 있는 그대로 검색하기에는 부적합** 할 수 있습니다.\n",
   "\n",
   "이런 경우, 실제로 우리가 하고 싶은 것은:\n",
   "1. 먼저 원시 문서를 더 큰 청크로 분할\n",
   "2. 그 다음, 더 작은 청크로 분할\n",
   "3. 작은 청크들을 인덱싱\n",
   "4. 검색 시에는 더 큰 청크를 검색 (그러나 여전히 전체 문서는 아님)\n",
   "\n",
   "- `RecursiveCharacterTextSplitter`를 사용하여 부모 문서와 자식 문서를 생성합니다.\n",
   "  - 부모 문서는 `chunk_size`가 1000으로 설정되어 있습니다.\n",
   "  - 자식 문서는 `chunk_size`가 200으로 설정되어 있으며, 부모 문서보다 작은 크기로 생성됩니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 13,
  "id": "create-splitters",
  "metadata": {},
  "outputs": [],
  "source": [
   "# 부모 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
   "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
   "# 자식 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
   "# 부모보다 작은 문서를 생성해야 합니다.\n",
   "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
   "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소입니다.\n",
   "vectorstore = Chroma(\n",
   "    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n",
   ")\n",
   "# 부모 문서의 저장 계층입니다.\n",
   "store = InMemoryStore()"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "init-parent-retriever",
  "metadata": {},
  "source": [
   "### 계층적 ParentDocumentRetriever 초기화\n",
   "\n",
   "`ParentDocumentRetriever`를 초기화하는 코드입니다.\n",
   "\n",
   "- `vectorstore` 매개변수는 문서 벡터를 저장하는 벡터 저장소를 지정합니다.\n",
   "- `docstore` 매개변수는 문서 데이터를 저장하는 문서 저장소를 지정합니다.\n",
   "- `child_splitter` 매개변수는 하위 문서를 분할하는 데 사용되는 문서 분할기를 지정합니다.\n",
   "- `parent_splitter` 매개변수는 상위 문서를 분할하는 데 사용되는 문서 분할기를 지정합니다.\n",
   "\n",
   "`ParentDocumentRetriever`는 계층적 문서 구조를 처리하며, 상위 문서와 하위 문서를 별도로 분할하고 저장합니다. 이를 통해 검색 시 상위 문서와 하위 문서를 효과적으로 활용할 수 있습니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 14,
  "id": "init-hierarchical-retriever",
  "metadata": {},
  "outputs": [],
  "source": [
   "retriever = ParentDocumentRetriever(\n",
   "    # 벡터 저장소를 지정합니다.\n",
   "    vectorstore=vectorstore,\n",
   "    # 문서 저장소를 지정합니다.\n",
   "    docstore=store,\n",
   "    # 하위 문서 분할기를 지정합니다.\n",
   "    child_splitter=child_splitter,\n",
   "    # 상위 문서 분할기를 지정합니다.\n",
   "    parent_splitter=parent_splitter,\n",
   ")"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 15,
  "id": "add-docs-hierarchical",
  "metadata": {},
  "outputs": [],
  "source": [
   "retriever.add_documents(docs)  # 문서를 retriever에 추가합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 16,
  "id": "check-store-keys-2",
  "metadata": {},
  "outputs": [
   {
    "data": {
     "text/plain": [
      "7"
     ]
    },
    "execution_count": 16,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "# 저장소에서 키를 생성하고 리스트로 변환한 후 길이를 반환합니다.\n",
   "len(list(store.yield_keys()))"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "verify-small-chunks",
  "metadata": {},
  "source": [
   "### 벡터 저장소가 여전히 작은 청크를 검색하는지 확인"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 17,
  "id": "verify-small-chunks-search",
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
     "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
     "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n"
    ]
   }
  ],
  "source": [
   "# 유사도 검색을 수행합니다.\n",
   "sub_docs = vectorstore.similarity_search(\"Word2Vec\")\n",
   "# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
   "print(sub_docs[0].page_content)"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "final-retrieval",
  "metadata": {},
  "source": [
   "### 계층적 Retriever를 통한 검색\n",
   "\n",
   "이번에는 `retriever` 객체의 `invoke()` 메서드를 사용하여 문서를 검색합니다.\n",
   "작은 청크로 검색하되, 해당 청크가 속한 더 큰 부모 청크를 반환합니다."
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 18,
  "id": "final-retrieval-search",
  "metadata": {},
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\n",
     "예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\n",
     "연관키워드: 딥러닝, 자연어 처리, Attention\n",
     "\n",
     "HuggingFace\n",
     "\n",
     "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
     "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
     "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
     "\n",
     "Digital Transformation\n",
     "\n",
     "정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\n",
     "예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
     "연관키워드: 혁신, 기술, 비즈니스 모델\n",
     "\n",
     "Crawling\n",
     "\n",
     "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
     "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
     "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
     "\n",
     "Word2Vec\n",
     "\n",
     "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
     "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
     "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
     "LLM (Large Language Model)\n"
    ]
   }
  ],
  "source": [
   "# 문서를 검색하여 가져옵니다.\n",
   "retrieved_docs = retriever.invoke(\"Word2Vec\")\n",
   "\n",
   "# 검색된 문서의 첫 번째 문서의 페이지 내용의 길이를 반환합니다.\n",
   "print(retrieved_docs[0].page_content)"
  ]
 },
 {
  "cell_type": "markdown",
  "id": "summary-section",
  "metadata": {},
  "source": [
   "## 6. 요약 및 핵심 포인트\n",
   "\n",
   "### ParentDocumentRetriever의 장점\n",
   "\n",
   "1. **검색 정확도 향상**: 작은 청크로 정확한 의미 매칭\n",
   "2. **맥락 보존**: 큰 청크 반환으로 전체 맥락 유지\n",
   "3. **유연한 구조**: 다양한 크기의 parent/child splitter 조합 가능\n",
   "\n",
   "### 주요 사용 사례\n",
   "\n",
   "- 긴 문서에서 특정 정보를 찾되, 전체 맥락이 필요한 경우\n",
   "- 기술 문서, 법률 문서 등 세부 내용과 전체 맥락이 모두 중요한 경우\n",
   "- RAG 시스템에서 검색 품질을 향상시키고자 할 때\n",
   "\n",
   "### 실습 결과 비교\n",
   "\n",
   "| 구분 | child_splitter만 사용 | parent_splitter 추가 사용 |\n",
   "|------|---------------------|------------------------|\n",
   "| 반환 문서 크기 | 전체 문서 (5733자) | 부모 청크 (약 1000자) |\n",
   "| 검색 정확도 | 높음 | 높음 |\n",
   "| 맥락 정보 | 과도함 | 적절함 |\n",
   "| 처리 효율성 | 낮음 | 높음 |"
  ]
 }
],
"metadata": {
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.11.0"
 }
},
"nbformat": 4,
"nbformat_minor": 5
}