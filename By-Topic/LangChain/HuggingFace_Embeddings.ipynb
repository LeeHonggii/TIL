{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255ef5d3",
   "metadata": {},
   "source": [
    "# HuggingFace Embeddings\n",
    "\n",
    "이 노트북에서는 LangChain에서 HuggingFace의 임베딩 모델을 활용하는 방법을 학습합니다.\n",
    "\n",
    "## 학습 내용\n",
    "- HuggingFace 임베딩 모델 설정\n",
    "- 텍스트를 벡터로 변환하는 방법\n",
    "- 다양한 임베딩 모델 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## 1. 환경 설정\n",
    "\n",
    "먼저 필요한 라이브러리를 설치하고 API 키를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7169ac69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "## 2. HuggingFace Embeddings 기본 사용법\n",
    "\n",
    "### 2.1 필요한 패키지 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings as HFEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "### 2.2 기본 임베딩 모델 초기화\n",
    "\n",
    "HuggingFace의 기본 임베딩 모델을 사용하여 텍스트를 벡터로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 모델 사용 (sentence-transformers/all-MiniLM-L6-v2)\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# 텍스트를 임베딩으로 변환\n",
    "text = \"안녕하세요, HuggingFace 임베딩을 학습하고 있습니다.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "# 임베딩 벡터의 차원 확인\n",
    "print(f\"임베딩 벡터 차원: {len(query_result)}\")\n",
    "print(f\"임베딩 벡터 일부: {query_result[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "### 2.3 특정 모델 지정하기\n",
    "\n",
    "다양한 HuggingFace 임베딩 모델을 지정하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어에 특화된 모델 사용\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# 한국어 텍스트 임베딩\n",
    "korean_text = \"자연어 처리는 인공지능의 중요한 분야입니다.\"\n",
    "korean_embedding = hf_embeddings.embed_query(korean_text)\n",
    "\n",
    "print(f\"한국어 임베딩 차원: {len(korean_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p7q8r9s0",
   "metadata": {},
   "source": [
    "## 3. 여러 문서 임베딩\n",
    "\n",
    "여러 문서를 한 번에 임베딩하는 방법을 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6f7g8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 문서 준비\n",
    "documents = [\n",
    "    \"LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다.\",\n",
    "    \"HuggingFace는 다양한 사전 학습된 모델을 제공합니다.\",\n",
    "    \"임베딩은 텍스트를 숫자 벡터로 변환하는 과정입니다.\",\n",
    "    \"벡터 데이터베이스는 임베딩을 효율적으로 저장하고 검색합니다.\"\n",
    "]\n",
    "\n",
    "# 문서들을 임베딩으로 변환\n",
    "doc_embeddings = hf_embeddings.embed_documents(documents)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"임베딩된 문서 수: {len(doc_embeddings)}\")\n",
    "print(f\"각 문서의 임베딩 차원: {len(doc_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t1u2v3w4",
   "metadata": {},
   "source": [
    "## 4. 임베딩 유사도 계산\n",
    "\n",
    "생성된 임베딩 벡터 간의 유사도를 계산하여 문서 간 관련성을 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7g8h9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 쿼리와 문서들 간의 유사도 계산\n",
    "query = \"LLM 프레임워크에 대해 알려주세요.\"\n",
    "query_embedding = hf_embeddings.embed_query(query)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "# 결과 출력\n",
    "for i, (doc, sim) in enumerate(zip(documents, similarities)):\n",
    "    print(f\"문서 {i+1} (유사도: {sim:.4f}): {doc}\")\n",
    "\n",
    "# 가장 유사한 문서 찾기\n",
    "most_similar_idx = np.argmax(similarities)\n",
    "print(f\"\\n가장 유사한 문서: {documents[most_similar_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x5y6z7a8",
   "metadata": {},
   "source": [
    "## 5. 다양한 임베딩 모델 비교\n",
    "\n",
    "여러 임베딩 모델의 성능과 특징을 비교해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7g8h9i0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교할 모델들\n",
    "models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",  # 영어 범용\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",  # 다국어\n",
    "    \"jhgan/ko-sroberta-multitask\"  # 한국어 특화\n",
    "]\n",
    "\n",
    "test_texts = [\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"기계 학습은 매우 흥미롭습니다.\",\n",
    "    \"機械学習は魅力的です。\"\n",
    "]\n",
    "\n",
    "# 각 모델로 임베딩 생성 및 비교\n",
    "for model_name in models:\n",
    "    print(f\"\\n모델: {model_name}\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    \n",
    "    for text in test_texts:\n",
    "        try:\n",
    "            embedding = embeddings.embed_query(text)\n",
    "            print(f\"  텍스트: {text[:30]}... -> 차원: {len(embedding)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  텍스트: {text[:30]}... -> 오류: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0d1e2",
   "metadata": {},
   "source": [
    "## 6. 캐싱을 통한 성능 최적화\n",
    "\n",
    "임베딩 결과를 캐싱하여 동일한 텍스트에 대한 반복 계산을 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g8h9i0j1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "import time\n",
    "\n",
    "# 캐시 저장소 설정\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# 기본 임베딩 모델\n",
    "underlying_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 캐시 백엔드 임베딩 생성\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings, store, namespace=underlying_embeddings.model_name\n",
    ")\n",
    "\n",
    "# 성능 테스트\n",
    "test_text = \"이것은 캐싱 테스트를 위한 문장입니다.\"\n",
    "\n",
    "# 첫 번째 실행 (캐시 없음)\n",
    "start_time = time.time()\n",
    "embedding1 = cached_embeddings.embed_query(test_text)\n",
    "first_time = time.time() - start_time\n",
    "\n",
    "# 두 번째 실행 (캐시 사용)\n",
    "start_time = time.time()\n",
    "embedding2 = cached_embeddings.embed_query(test_text)\n",
    "second_time = time.time() - start_time\n",
    "\n",
    "print(f\"첫 번째 실행 시간: {first_time:.4f}초\")\n",
    "print(f\"두 번째 실행 시간 (캐시): {second_time:.4f}초\")\n",
    "print(f\"속도 향상: {first_time/second_time:.2f}배\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3g4h5i6",
   "metadata": {},
   "source": [
    "## 7. 실제 활용 예제: 문서 검색 시스템\n",
    "\n",
    "HuggingFace 임베딩을 활용한 간단한 문서 검색 시스템을 구현해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h9i0j1k2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDocumentSearch:\n",
    "    def __init__(self, model_name=\"jhgan/ko-sroberta-multitask\"):\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        self.documents = []\n",
    "        self.doc_embeddings = []\n",
    "    \n",
    "    def add_documents(self, documents):\n",
    "        \"\"\"문서를 추가하고 임베딩을 생성합니다.\"\"\"\n",
    "        self.documents.extend(documents)\n",
    "        new_embeddings = self.embeddings.embed_documents(documents)\n",
    "        self.doc_embeddings.extend(new_embeddings)\n",
    "    \n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"쿼리와 가장 유사한 문서를 검색합니다.\"\"\"\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        \n",
    "        # 유사도 계산\n",
    "        similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "        \n",
    "        # 상위 k개 문서 선택\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'document': self.documents[idx],\n",
    "                'similarity': similarities[idx]\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# 문서 검색 시스템 사용 예제\n",
    "search_system = SimpleDocumentSearch()\n",
    "\n",
    "# 문서 추가\n",
    "knowledge_base = [\n",
    "    \"Python은 배우기 쉽고 강력한 프로그래밍 언어입니다.\",\n",
    "    \"JavaScript는 웹 개발에 필수적인 언어입니다.\",\n",
    "    \"기계학습은 데이터에서 패턴을 찾는 기술입니다.\",\n",
    "    \"딥러닝은 인공 신경망을 사용하는 기계학습의 한 분야입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하도록 하는 기술입니다.\"\n",
    "]\n",
    "\n",
    "search_system.add_documents(knowledge_base)\n",
    "\n",
    "# 검색 수행\n",
    "query = \"인공지능과 관련된 기술을 알려주세요\"\n",
    "results = search_system.search(query, top_k=3)\n",
    "\n",
    "print(f\"쿼리: {query}\\n\")\n",
    "print(\"검색 결과:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. 유사도: {result['similarity']:.4f}\")\n",
    "    print(f\"   문서: {result['document']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j2k3l4m5",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "이 노트북에서는 LangChain에서 HuggingFace 임베딩을 활용하는 방법을 학습했습니다:\n",
    "\n",
    "1. **기본 사용법**: HuggingFaceEmbeddings 클래스를 사용한 텍스트 임베딩\n",
    "2. **모델 선택**: 다양한 임베딩 모델 (영어, 한국어, 다국어) 활용\n",
    "3. **문서 임베딩**: 여러 문서를 한 번에 임베딩하는 방법\n",
    "4. **유사도 계산**: 코사인 유사도를 이용한 문서 관련성 측정\n",
    "5. **성능 최적화**: 캐싱을 통한 임베딩 계산 최적화\n",
    "6. **실제 활용**: 간단한 문서 검색 시스템 구현\n",
    "\n",
    "HuggingFace 임베딩은 RAG(Retrieval-Augmented Generation) 시스템, 의미 기반 검색, 문서 분류 등 다양한 NLP 애플리케이션에서 핵심적인 역할을 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}