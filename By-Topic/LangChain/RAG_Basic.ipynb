{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation) 기초 구현\n",
    "\n",
    "## 📚 개요\n",
    "\n",
    "RAG는 대규모 언어 모델(LLM)의 한계를 극복하기 위한 기술입니다.\n",
    "\n",
    "### 🎯 RAG를 사용하는 이유\n",
    "- **할루시네이션 방지**: 최신 정보나 학습되지 않은 정보에 대한 잘못된 답변 생성 방지\n",
    "- **정확한 정보 제공**: 실제 문서를 기반으로 한 답변 생성\n",
    "- **맞춤형 지식 활용**: 특정 도메인이나 조직의 문서를 활용한 답변\n",
    "\n",
    "### 🔄 RAG 진행 순서\n",
    "1. **문서 로드** (Document Loading)\n",
    "2. **텍스트 분할** (Text Splitting) - 청크 단위로 분할\n",
    "3. **임베딩** (Embedding) - 텍스트를 벡터로 수치화\n",
    "4. **벡터 저장** (Vector Storage)\n",
    "5. **검색** (Retrieval) - 질문에 해당하는 문서 검색\n",
    "6. **답변 생성** (Generation) - 검색된 문서를 기반으로 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 1: 문서 로드 (Load Documents)\n",
    "\n",
    "PDF 문서를 로드하여 처리 가능한 형태로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지수: 5\n"
     ]
    }
   ],
   "source": [
    "# PyMuPDFLoader를 사용하여 PDF 파일 로드\n",
    "loader = PyMuPDFLoader(\"../data/data.pdf\")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 페이지수: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📄 문서 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 페이지의 내용 확인 (예: 3번째 페이지)\n",
    "# print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏷️ 메타데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서의 메타데이터 정보 확인\n",
    "# docs[2].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 2: 문서 분할 (Split Documents)\n",
    "\n",
    "긴 문서를 작은 청크로 분할하여 검색과 처리를 효율적으로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의수: 25\n"
     ]
    }
   ],
   "source": [
    "# RecursiveCharacterTextSplitter를 사용하여 텍스트 분할\n",
    "# chunk_size: 각 청크의 최대 크기\n",
    "# chunk_overlap: 청크 간 중복되는 문자 수 (문맥 유지를 위해)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"분할된 청크의수: {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 3: 임베딩 (Embedding) 생성\n",
    "\n",
    "텍스트를 벡터로 변환하여 의미적 유사성을 계산할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 임베딩 모델 사용\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 4: 벡터 데이터베이스 생성 및 저장\n",
    "\n",
    "임베딩된 문서를 벡터 데이터베이스에 저장하여 빠른 검색을 가능하게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS (Facebook AI Similarity Search) 벡터스토어 생성\n",
    "# 문서와 임베딩을 함께 저장\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 유사도 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 키워드로 유사한 문서 검색 테스트\n",
    "# for doc in vectorstore.similarity_search(\"하향식설계\"):\n",
    "#     print(doc.page_content)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 5: 검색기 (Retriever) 생성\n",
    "\n",
    "벡터스토어를 검색 가능한 형태로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어를 검색기로 변환\n",
    "# 기본적으로 가장 유사한 4개의 문서를 반환\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 검색기 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기에 쿼리를 날려 검색된 chunk 결과를 확인\n",
    "# retriever.invoke(\"요구사항 개발 프로세스의 순서는 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 6: 프롬프트 템플릿 생성\n",
    "\n",
    "LLM에 전달할 프롬프트의 구조를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 프롬프트 템플릿\n",
    "# context: 검색된 문서 내용\n",
    "# question: 사용자의 질문\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 7: 언어 모델 (LLM) 생성\n",
    "\n",
    "답변을 생성할 언어 모델을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI 모델 생성\n",
    "# temperature=0: 일관된 답변을 위해 무작위성 제거\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 8: RAG 체인 생성\n",
    "\n",
    "모든 구성 요소를 연결하여 완전한 RAG 파이프라인을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL (LangChain Expression Language)을 사용한 체인 구성\n",
    "chain = (\n",
    "    # 입력 처리: context는 retriever에서, question은 그대로 전달\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    # 프롬프트 적용\n",
    "    | prompt\n",
    "    # LLM으로 답변 생성\n",
    "    | llm\n",
    "    # 출력을 문자열로 파싱\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 RAG 체인 실행\n",
    "\n",
    "구성된 RAG 시스템을 사용하여 질문에 답변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 요구사항의 유형의 비기능적요구는 무엇이 있나요?\n",
      "\n",
      "답변: 비기능적 요구에는 성능, 보안, 품질, 안정성 등이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질문 설정 및 체인 실행\n",
    "question = \"요구사항의 유형의 비기능적요구는 무엇이 있나요?\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(f\"질문: {question}\")\n",
    "print(f\"\\n답변: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 추가 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 요구사항 개발 프로세스의 순서는 무엇인가요?\n",
      "답변: 요구사항 개발 프로세스의 순서는 다음과 같습니다:\n",
      "\n",
      "1. 도출(Elicitation)\n",
      "2. 분석(Analysis) \n",
      "3. 명세(Specification)\n",
      "4. 확인(Validation)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다른 질문으로 테스트\n",
    "questions = [\n",
    "    \"요구사항 개발 프로세스의 순서는 무엇인가요?\",\n",
    "    # \"하향식 설계에 대해 설명해주세요.\",\n",
    "    # \"소프트웨어 개발 방법론에는 어떤 것들이 있나요?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    response = chain.invoke(q)\n",
    "    print(f\"\\n질문: {q}\")\n",
    "    print(f\"답변: {response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 핵심 개념 정리\n",
    "\n",
    "### RAG의 주요 구성 요소\n",
    "\n",
    "1. **Document Loader**: 다양한 형식의 문서를 로드\n",
    "   - PyMuPDFLoader: PDF 파일 처리\n",
    "   - 다른 로더들: TextLoader, CSVLoader, JSONLoader 등\n",
    "\n",
    "2. **Text Splitter**: 긴 문서를 작은 청크로 분할\n",
    "   - RecursiveCharacterTextSplitter: 가장 일반적인 분할기\n",
    "   - chunk_size와 chunk_overlap 파라미터로 조정\n",
    "\n",
    "3. **Embeddings**: 텍스트를 벡터로 변환\n",
    "   - OpenAIEmbeddings: OpenAI의 임베딩 모델 사용\n",
    "   - 의미적 유사성 계산 가능\n",
    "\n",
    "4. **Vector Store**: 임베딩된 문서 저장 및 검색\n",
    "   - FAISS: 효율적인 유사도 검색\n",
    "   - 다른 옵션: Chroma, Pinecone, Weaviate 등\n",
    "\n",
    "5. **Retriever**: 벡터스토어에서 관련 문서 검색\n",
    "   - 기본적으로 코사인 유사도 기반 검색\n",
    "\n",
    "6. **LLM Chain**: 검색된 문서를 기반으로 답변 생성\n",
    "   - 프롬프트 템플릿과 LLM을 연결\n",
    "   - LCEL로 파이프라인 구성\n",
    "\n",
    "### 💡 활용 팁\n",
    "\n",
    "- **청크 크기 조정**: 문서의 특성에 따라 chunk_size 조정\n",
    "- **오버랩 설정**: chunk_overlap으로 문맥 유지\n",
    "- **검색 개수 조정**: retriever의 k 파라미터로 검색 문서 수 조정\n",
    "- **프롬프트 최적화**: 도메인에 맞는 프롬프트 템플릿 작성"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
