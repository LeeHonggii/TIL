{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlashRank Reranker로 문서 재순위화\n",
    "\n",
    "## 개요\n",
    "FlashRank는 검색 및 retrieval 파이프라인에 재순위를 추가하기 위한 초경량 및 초고속 Python 라이브러리입니다. 이 노트북에서는 FlashRank를 사용하여 문서 압축 및 retrieval을 수행하는 방법을 알아봅니다.\n",
    "\n",
    "### 주요 특징\n",
    "- **초경량**: 최소한의 메모리 사용\n",
    "- **초고속**: 빠른 재순위 처리\n",
    "- **SoTA cross-encoders 기반**: 최신 cross-encoder 모델 활용\n",
    "- **쉬운 통합**: LangChain과 원활한 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 설치\n",
    "# !pip install -qU flashrank\n",
    "# !pip install -qU langchain langchain-community langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 설정 (필요시)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 유틸리티 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    \"\"\"문서를 보기 좋게 출력하는 유틸리티 함수\"\"\"\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 로드\n",
    "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
    "\n",
    "# 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # 청크 크기\n",
    "    chunk_overlap=100    # 청크 간 중복\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# 각 텍스트에 고유 ID 추가\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n",
    "\n",
    "print(f\"총 {len(texts)}개의 텍스트 청크가 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 벡터 스토어 및 기본 Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# FAISS 벡터 스토어 생성\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# 기본 retriever 생성 (상위 10개 문서 검색)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 기본 Retriever 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의문\n",
    "query = \"Word2Vec에 대해서 설명해줘.\"\n",
    "\n",
    "# 기본 retriever로 문서 검색\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n질의: {query}\")\n",
    "print(f\"\\n검색된 문서 개수: {len(docs)}\")\n",
    "print(f\"검색된 문서 ID: {[doc.metadata['id'] for doc in docs]}\")\n",
    "print(\"\\n=== 검색된 문서 내용 ===\\n\")\n",
    "pretty_print_docs(docs[:3])  # 상위 3개만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FlashRank Reranker 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "# FlashRank reranker 초기화\n",
    "# ms-marco-MultiBERT-L-12: MS MARCO 데이터셋으로 학습된 다국어 BERT 모델\n",
    "compressor = FlashrankRerank(\n",
    "    model=\"ms-marco-MultiBERT-L-12\",\n",
    "    top_n=3  # 상위 3개 문서만 반환 (옵션)\n",
    ")\n",
    "\n",
    "# ContextualCompressionRetriever로 래핑\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reranker 적용 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlashRank reranker로 압축된 문서 검색\n",
    "compressed_docs = compression_retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n질의: {query}\")\n",
    "print(f\"\\n재순위화 후 문서 개수: {len(compressed_docs)}\")\n",
    "print(f\"재순위화 후 문서 ID: {[doc.metadata['id'] for doc in compressed_docs]}\")\n",
    "print(\"\\n=== 재순위화된 문서 내용 ===\\n\")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Relevance Score 확인\n",
    "\n",
    "FlashRank는 각 문서에 relevance score를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance score 확인\n",
    "print(\"\\n=== Relevance Scores ===\\n\")\n",
    "for i, doc in enumerate(compressed_docs):\n",
    "    score = doc.metadata.get('relevance_score', 'N/A')\n",
    "    doc_id = doc.metadata.get('id', 'N/A')\n",
    "    print(f\"Document {i+1} (ID: {doc_id}): Score = {score:.6f}\")\n",
    "    # 문서 내용의 첫 100자만 출력\n",
    "    preview = doc.page_content[:100] + \"...\"\n",
    "    print(f\"  Preview: {preview}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 다양한 쿼리로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 쿼리 테스트\n",
    "test_queries = [\n",
    "    \"임베딩이란 무엇인가?\",\n",
    "    \"딥러닝과 머신러닝의 차이점\",\n",
    "    \"판다스 DataFrame 사용법\"\n",
    "]\n",
    "\n",
    "for test_query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"질의: {test_query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 기본 retriever\n",
    "    basic_docs = retriever.invoke(test_query)\n",
    "    print(f\"\\n기본 Retriever - 상위 3개 문서 ID: {[doc.metadata['id'] for doc in basic_docs[:3]]}\")\n",
    "    \n",
    "    # FlashRank reranker\n",
    "    reranked_docs = compression_retriever.invoke(test_query)\n",
    "    print(f\"FlashRank Reranker - 상위 3개 문서 ID: {[doc.metadata['id'] for doc in reranked_docs[:3]]}\")\n",
    "    \n",
    "    # Relevance scores\n",
    "    scores = [doc.metadata.get('relevance_score', 0) for doc in reranked_docs[:3]]\n",
    "    print(f\"Relevance Scores: {[f'{score:.4f}' for score in scores]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. RAG 파이프라인에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# 기본 retriever를 사용한 QA 체인\n",
    "basic_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# FlashRank reranker를 사용한 QA 체인\n",
    "reranked_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문\n",
    "question = \"Word2Vec의 정의와 예시를 설명해주세요.\"\n",
    "\n",
    "print(f\"질문: {question}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 기본 retriever 결과\n",
    "print(\"\\n### 기본 Retriever 사용 ###\")\n",
    "basic_result = basic_qa.invoke({\"query\": question})\n",
    "print(f\"답변: {basic_result['result']}\")\n",
    "print(f\"\\n사용된 문서 수: {len(basic_result['source_documents'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# FlashRank reranker 결과\n",
    "print(\"\\n### FlashRank Reranker 사용 ###\")\n",
    "reranked_result = reranked_qa.invoke({\"query\": question})\n",
    "print(f\"답변: {reranked_result['result']}\")\n",
    "print(f\"\\n사용된 문서 수: {len(reranked_result['source_documents'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_retrieval_time(retriever, query, n_runs=5):\n",
    "    \"\"\"Retriever의 평균 실행 시간을 측정\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        _ = retriever.invoke(query)\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    return sum(times) / len(times)\n",
    "\n",
    "# 성능 측정\n",
    "query = \"임베딩과 벡터화에 대해 설명해줘\"\n",
    "\n",
    "basic_time = measure_retrieval_time(retriever, query)\n",
    "reranked_time = measure_retrieval_time(compression_retriever, query)\n",
    "\n",
    "print(\"\\n=== 성능 비교 ===\")\n",
    "print(f\"기본 Retriever 평균 시간: {basic_time:.4f}초\")\n",
    "print(f\"FlashRank Reranker 평균 시간: {reranked_time:.4f}초\")\n",
    "print(f\"추가 소요 시간: {reranked_time - basic_time:.4f}초\")\n",
    "print(f\"\\n* FlashRank는 초경량 모델이므로 추가 시간이 매우 적습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. FlashRank 모델 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 FlashRank 모델 테스트\n",
    "models = [\n",
    "    \"ms-marco-TinyBERT-L-2-v2\",      # 가장 작은 모델\n",
    "    \"ms-marco-MiniLM-L-12-v2\",       # 중간 크기 모델\n",
    "    \"ms-marco-MultiBERT-L-12\",       # 다국어 지원 모델\n",
    "]\n",
    "\n",
    "print(\"\\n=== FlashRank 모델 비교 ===\")\n",
    "print(f\"질의: {query}\\n\")\n",
    "\n",
    "for model_name in models:\n",
    "    try:\n",
    "        # 모델별 compressor 생성\n",
    "        model_compressor = FlashrankRerank(\n",
    "            model=model_name,\n",
    "            top_n=3\n",
    "        )\n",
    "        \n",
    "        # Compression retriever 생성\n",
    "        model_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=model_compressor,\n",
    "            base_retriever=retriever\n",
    "        )\n",
    "        \n",
    "        # 시간 측정\n",
    "        start = time.time()\n",
    "        docs = model_retriever.invoke(query)\n",
    "        end = time.time()\n",
    "        \n",
    "        print(f\"\\n모델: {model_name}\")\n",
    "        print(f\"  - 실행 시간: {end - start:.4f}초\")\n",
    "        print(f\"  - 상위 문서 ID: {[doc.metadata['id'] for doc in docs[:3]]}\")\n",
    "        if docs and 'relevance_score' in docs[0].metadata:\n",
    "            print(f\"  - 최고 점수: {docs[0].metadata['relevance_score']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n모델 {model_name} 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "### FlashRank Reranker의 장점\n",
    "\n",
    "1. **초경량 & 초고속**: 매우 작은 모델 크기와 빠른 처리 속도\n",
    "2. **높은 정확도**: Cross-encoder 기반으로 우수한 재순위화 성능\n",
    "3. **쉬운 통합**: LangChain의 ContextualCompressionRetriever와 원활한 통합\n",
    "4. **다국어 지원**: MultiBERT 모델을 통한 다국어 문서 처리\n",
    "\n",
    "### 사용 시나리오\n",
    "\n",
    "- **RAG 파이프라인 개선**: 검색된 문서의 품질 향상\n",
    "- **리소스 제한 환경**: 서버리스, 엣지 디바이스 등에서 사용\n",
    "- **실시간 애플리케이션**: 빠른 응답이 필요한 서비스\n",
    "- **대규모 문서 처리**: 많은 문서 중 가장 관련성 높은 것만 선별\n",
    "\n",
    "### 주의사항\n",
    "\n",
    "- FlashRank는 재순위화만 수행하므로 초기 retrieval 품질이 중요\n",
    "- top_n 파라미터로 반환할 문서 수 조절 가능\n",
    "- 모델 선택 시 속도와 정확도 간 트레이드오프 고려"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}