{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yaml파일로 템플릿 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['fruit'], template='{fruit}의 색깔이 뭐야?')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompts/fruit_color.yaml\", encoding=\"utf-8\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과의 색깔이 뭐야?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(fruit=\"사과\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도에 대해서 알려주세요.\n",
      "수도의 특징을 다음의 양식에 맞게 정리해 주세요.\n",
      "300자 내외로 작성해 주세요.\n",
      "한글로 작성해 주세요.\n",
      "----\n",
      "[양식]\n",
      "1. 면적\n",
      "2. 인구\n",
      "3. 역사적 장소\n",
      "4. 특산품\n",
      "\n",
      "#Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
    "print(prompt2.format(country=\"대한민국\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 면적: 대한민국의 수도인 서울특별시는 약 605.21 km²의 면적을 가지고 있습니다. 이는 전국에서 가장 큰 도시 중 하나로, 다양한 행정구역과 자연경관을 포함하고 있습니다.\n",
      "\n",
      "2. 인구: 서울의 인구는 약 950만 명으로, 대한민국에서 가장 인구가 많은 도시입니다. 다양한 문화와 경제 활동의 중심지로서 많은 사람들이 거주하고 있습니다.\n",
      "\n",
      "3. 역사적 장소: 서울에는 경복궁, 창덕궁, 덕수궁 등 조선시대의 궁궐들이 있으며, 한양도성, 종묘 등 유네스코 세계문화유산으로 지정된 역사적 장소들이 많습니다. 이러한 장소들은 서울의 오랜 역사와 문화를 보여줍니다.\n",
      "\n",
      "4. 특산품: 서울은 전통과 현대가 조화를 이루는 도시로, 한복, 한지 공예품, 전통 음식인 김치와 떡 등이 유명합니다. 또한, 현대적인 패션과 기술 제품들도 서울의 특산품으로 인기를 끌고 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = (\n",
    "    prompt2 | \n",
    "    ChatOpenAI(model_name=\"gpt-4o\", temperature=0) | \n",
    "    StrOutputParser()\n",
    ")\n",
    "for chunk in chain.stream({\"country\": \"대한민국\"}):\n",
    "    print(chunk, end=\"\")  # 실시간으로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatpromptTemplate\n",
    "대화형형식의 템플릿을 사용하고싶을때 역활을 부여하고 사용하는것\n",
    "**role**\n",
    "- `\"system\"`: 시스템 설정 메시지 입니다. -페르소나부여\n",
    "- `\"human\"` : 사용자 입력 메시지 입니다.\n",
    "- `\"ai\"`: AI 의 답변 메시지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 테디 입니다.'),\n",
       " HumanMessage(content='반가워요!'),\n",
       " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?'),\n",
       " HumanMessage(content='당신의 이름은 무엇입니까?')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\"),\n",
    "        (\"human\", \"반가워요!\"),\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 챗 message 를 생성합니다.\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"테디\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저는 테디입니다. 무엇이든 질문이 있으면 언제든지 물어보세요!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MessagePlaceholder\n",
    "메시지 프롬프트 템플릿에 어떤 역할을 사용해야 할지 확실하지 않거나 서식 지정 중에 메시지 목록을 삽입하려는 경우 유용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.')), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='지금까지의 대화를 {word_count} 단어로 요약합니다.'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\n",
      "Human: 안녕하세요! 저는 오늘 새로 입사한 홍기 입니다. 만나서 반갑습니다.\n",
      "AI: 반가워요! 앞으로 잘 부탁 드립니다.\n",
      "Human: 지금까지의 대화를 7 단어로 요약합니다.\n"
     ]
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=7,\n",
    "    conversation=[\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 홍기 입니다. 만나서 반갑습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성\n",
    "chain = chat_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'입사, 홍기, 인사, 반가움, 소개'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 실행 및 결과확인\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5,\n",
    "        \"conversation\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"안녕하세요! 저는 오늘 새로 입사한 홍기 입니다. 만나서 반갑습니다.\",\n",
    "            ),\n",
    "            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FewShotpromptTemplate\n",
    "\n",
    "하나의 답변예시로 보여주면 oneshot\n",
    "두개이상의 답변예시로 보여주면 Fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
    "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
    "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
    "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
    "최종 답변은: 아인슈타인\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"네이버의 창립자는 언제 태어났나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 네이버의 창립자는 누구인가요?\n",
    "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
    "추가 질문: 이해진은 언제 태어났나요?\n",
    "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
    "최종 답변은: 1967년 6월 22일\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
    "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
    "추가 질문: 신사임당은 언제 태어났나요?\n",
    "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
    "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
    "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
    "최종 답변은: 연산군\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"올드보이와 기생충의 감독이 같은 나라 출신인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 올드보이의 감독은 누구인가요?\n",
    "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
    "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
    "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
    "추가 질문: 기생충의 감독은 누구인가요?\n",
    "중간 답변: 기생충의 감독은 봉준호입니다.\n",
    "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
    "중간 답변: 봉준호는 대한민국 출신입니다.\n",
    "최종 답변은: 예\n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
      "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
      "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
      "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
      "최종 답변은: 아인슈타인\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"Question:\\n{question}\\nAnswer:\\n{answer}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
      "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
      "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
      "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
      "최종 답변은: 아인슈타인\n",
      "\n",
      "\n",
      "Question:\n",
      "네이버의 창립자는 언제 태어났나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 네이버의 창립자는 누구인가요?\n",
      "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
      "추가 질문: 이해진은 언제 태어났나요?\n",
      "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
      "최종 답변은: 1967년 6월 22일\n",
      "\n",
      "\n",
      "Question:\n",
      "율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
      "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
      "추가 질문: 신사임당은 언제 태어났나요?\n",
      "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
      "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
      "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
      "최종 답변은: 연산군\n",
      "\n",
      "\n",
      "Question:\n",
      "올드보이와 기생충의 감독이 같은 나라 출신인가요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 올드보이의 감독은 누구인가요?\n",
      "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
      "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
      "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
      "추가 질문: 기생충의 감독은 누구인가요?\n",
      "중간 답변: 기생충의 감독은 봉준호입니다.\n",
      "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
      "중간 답변: 봉준호는 대한민국 출신입니다.\n",
      "최종 답변은: 예\n",
      "\n",
      "\n",
      "Question:\n",
      "Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "final_prompt = prompt.format(question=question)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.  \n",
      "추가 질문: Google은 언제 창립되었나요?  \n",
      "중간 답변: Google은 1998년에 창립되었습니다.  \n",
      "추가 질문: Bill Gates는 언제 태어났나요?  \n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.  \n",
      "추가 질문: 1998년에는 Bill Gates가 몇 살이었나요?  \n",
      "중간 답변: 1998년에 Bill Gates는 43세였습니다.  \n",
      "최종 답변은: 43세"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 결과 출력\n",
    "answer = llm.stream(final_prompt)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Selector\n",
    "프롬포트에 들어갈 예제을 골라서 사용하는것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SemanticSimilarity : Fewshot에 넣을 예제을 유사도계산을 통해 하나를 선정하는것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxMarginalRelevance : 이전엔 유사도만 판단한거면 다양성과 관련성을 모두 고려해서 예시 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 가장 유사한 예시:\n",
      "Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n",
      "\n",
      "question:\n",
      "네이버의 창립자는 언제 태어났나요?\n",
      "answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 네이버의 창립자는 누구인가요?\n",
      "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
      "추가 질문: 이해진은 언제 태어났나요?\n",
      "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
      "최종 답변은: 1967년 6월 22일\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Vector DB 생성 (저장소 이름, 임베딩 클래스)\n",
    "chroma = Chroma(\"example_selector\", OpenAIEmbeddings())\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 여기에는 선택 가능한 예시 목록이 있습니다.\n",
    "    examples,\n",
    "    # 여기에는 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 여기에는 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n",
    "    Chroma,\n",
    "    # 이것은 생성할 예시의 수입니다.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "\n",
    "# 입력과 가장 유사한 예시를 선택합니다.\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "\n",
    "print(f\"입력에 가장 유사한 예시:\\n{question}\\n\")\n",
    "for example in selected_examples:\n",
    "    print(f'question:\\n{example[\"question\"]}')\n",
    "    print(f'answer:\\n{example[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.  \n",
      "추가 질문: Google은 언제 창립되었나요?  \n",
      "중간 답변: Google은 1998년에 창립되었습니다.  \n",
      "추가 질문: Bill Gates는 언제 태어났나요?  \n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.  \n",
      "계산: 1998년 - 1955년 = 43  \n",
      "최종 답변은: 43살입니다."
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "answer = chain.stream(\n",
    "    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",
    ")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FewShotChatMessagePromptTemplate\n",
    "Fewshot인데 메세지값을 하나 더 추가해서 사용하는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"instruction\": \"당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요\",\n",
    "        \"input\": \"2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.\",\n",
    "        \"answer\": \"\"\"\n",
    "회의록: XYZ 회사 마케팅 전략 회의\n",
    "일시: 2023년 12월 25일\n",
    "장소: XYZ 회사 회의실\n",
    "참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\n",
    "\n",
    "1. 개회\n",
    "   - 회의는 김수진 팀장의 개회사로 시작됨.\n",
    "   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\n",
    "\n",
    "2. 시장 동향 개요 (김수진)\n",
    "   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\n",
    "   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\n",
    "\n",
    "3. 디지털 마케팅 전략 (박지민)\n",
    "   - 박지민은 디지털 마케팅 전략에 대해 발표.\n",
    "   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\n",
    "\n",
    "4. 소셜 미디어 캠페인 (이준호)\n",
    "   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\n",
    "   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\n",
    "\n",
    "5. 종합 논의\n",
    "   - 팀원들 간의 아이디어 공유 및 토론.\n",
    "   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\n",
    "\n",
    "6. 마무리\n",
    "   - 다음 회의 날짜 및 시간 확정.\n",
    "   - 회의록 정리 및 배포는 박지민 담당.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 요약 전문가 입니다. 다음 주어진 정보를 바탕으로 내용을 요약해 주세요\",\n",
    "        \"input\": \"이 문서는 '지속 가능한 도시 개발을 위한 전략'에 대한 20페이지 분량의 보고서입니다. 보고서는 지속 가능한 도시 개발의 중요성, 현재 도시화의 문제점, 그리고 도시 개발을 지속 가능하게 만들기 위한 다양한 전략을 포괄적으로 다루고 있습니다. 이 보고서는 또한 성공적인 지속 가능한 도시 개발 사례를 여러 국가에서 소개하고, 이러한 사례들을 통해 얻은 교훈을 요약하고 있습니다.\",\n",
    "        \"answer\": \"\"\"\n",
    "문서 요약: 지속 가능한 도시 개발을 위한 전략 보고서\n",
    "\n",
    "- 중요성: 지속 가능한 도시 개발이 필수적인 이유와 그에 따른 사회적, 경제적, 환경적 이익을 강조.\n",
    "- 현 문제점: 현재의 도시화 과정에서 발생하는 주요 문제점들, 예를 들어 환경 오염, 자원 고갈, 불평등 증가 등을 분석.\n",
    "- 전략: 지속 가능한 도시 개발을 달성하기 위한 다양한 전략 제시. 이에는 친환경 건축, 대중교통 개선, 에너지 효율성 증대, 지역사회 참여 강화 등이 포함됨.\n",
    "- 사례 연구: 전 세계 여러 도시의 성공적인 지속 가능한 개발 사례를 소개. 예를 들어, 덴마크의 코펜하겐, 일본의 요코하마 등의 사례를 통해 실현 가능한 전략들을 설명.\n",
    "- 교훈: 이러한 사례들에서 얻은 주요 교훈을 요약. 강조된 교훈에는 다각적 접근의 중요성, 지역사회와의 협력, 장기적 계획의 필요성 등이 포함됨.\n",
    "\n",
    "이 보고서는 지속 가능한 도시 개발이 어떻게 현실적이고 효과적인 형태로 이루어질 수 있는지에 대한 심도 있는 분석을 제공합니다.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요\",\n",
    "        \"input\": \"우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.\",\n",
    "        \"answer\": \"본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma = Chroma(\"fewshot_chat\", OpenAIEmbeddings())\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{instruction}:\\n{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 여기에는 선택 가능한 예시 목록이 있습니다.\n",
    "    examples,\n",
    "    # 여기에는 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 여기에는 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n",
    "    chroma,\n",
    "    # 이것은 생성할 예시의 수입니다.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '\\n회의록: XYZ 회사 마케팅 전략 회의\\n일시: 2023년 12월 25일\\n장소: XYZ 회사 회의실\\n참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\\n\\n1. 개회\\n   - 회의는 김수진 팀장의 개회사로 시작됨.\\n   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\\n\\n2. 시장 동향 개요 (김수진)\\n   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\\n   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\\n\\n3. 디지털 마케팅 전략 (박지민)\\n   - 박지민은 디지털 마케팅 전략에 대해 발표.\\n   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\\n\\n4. 소셜 미디어 캠페인 (이준호)\\n   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\\n   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\\n\\n5. 종합 논의\\n   - 팀원들 간의 아이디어 공유 및 토론.\\n   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\\n\\n6. 마무리\\n   - 다음 회의 날짜 및 시간 확정.\\n   - 회의록 정리 및 배포는 박지민 담당.\\n',\n",
       "  'input': '2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.',\n",
       "  'instruction': '당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n",
    "}\n",
    "\n",
    "example_selector.select_examples(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{instruction}\\n{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의록: ABC 기술 회사 제품 개발 팀 주간 진행 상황 회의\n",
      "\n",
      "일시: 2023년 12월 26일  \n",
      "장소: ABC 기술 회사 회의실  \n",
      "참석자: 최현수 (프로젝트 매니저), 황지연 (주요 개발자), 김태영 (UI/UX 디자이너)\n",
      "\n",
      "1. 개회\n",
      "   - 최현수 프로젝트 매니저가 회의를 시작하고 회의의 목적을 설명함.\n",
      "   - 이번 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고 다가오는 마일스톤에 대한 계획을 수립하는 것임.\n",
      "\n",
      "2. 진행 상황 업데이트\n",
      "   - **최현수 (프로젝트 매니저)**: 전반적인 프로젝트 일정 확인 및 현재 진행 상황 요약. 현재까지의 주요 성과 및 문제점 공유.\n",
      "   - **황지연 (주요 개발자)**: 백엔드 개발의 현재 상태와 기술적 도전 과제 보고. 코드 최적화 및 버그 수정 상황 설명.\n",
      "   - **김태영 (UI/UX 디자이너)**: 사용자 인터페이스 디자인의 진행 상황을 설명하고, 최근 사용자 테스트 결과를 공유. 디자인 수정 사항 논의.\n",
      "\n",
      "3. 다가오는 마일스톤 계획\n",
      "   - 각 팀원은 다음 주까지의 목표를 설정하고 이에 대한 세부 계획을 논의함.\n",
      "   - 황지연은 개발 일정에 맞춰 특정 모듈 완성을 목표로 설정.\n",
      "   - 김태영은 디자인 피드백을 반영하여 수정된 UI를 제출할 계획.\n",
      "\n",
      "4. 종합 논의\n",
      "   - 프로젝트의 전반적인 진행에 대한 팀원 간의 토론.\n",
      "   - 리소스 배분 및 협업 필요성 논의.\n",
      "\n",
      "5. 마무리\n",
      "   - 다음 주 회의 일정 조율 및 확정.\n",
      "   - 회의록 작성 및 배포 담당자 지정: 최현수 담당.\n",
      "\n",
      "회의는 원활하게 진행되었으며, 팀은 설정된 목표를 달성하기 위해 협력할 것을 다짐하며 종료됨."
     ]
    }
   ],
   "source": [
    "# chain 생성\n",
    "chain = final_prompt | llm\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "answer = chain.stream(question)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangchainHub로부터 Prompt 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\userpc\\.conda\\envs\\teddychain\\Lib\\site-packages\\langsmith\\client.py:5434: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  prompt = loads(json.dumps(prompt_object.manifest))\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 가장 최신 버전의 프롬프트를 가져옵니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 내용 출력\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 버전의 프롬프트를 가져오려면 버전 해시를 지정하세요\n",
    "prompt = hub.pull(\"rlm/rag-prompt:50442af1\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\n\\nCONTEXT: {context}\\n\\nSUMMARY:'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\"\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/honggitest/1ab92208?organizationId=c36c1a95-0ab7-5fad-9fb5-b2de80a5d749'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 프롬프트를 허브에 업로드합니다.\n",
    "hub.push(\"hoggi/honggitest\", prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teddychain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
